{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKa6sMyI_wXK"
      },
      "source": [
        "# 2. OpenAI의 챗 API 기초\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk1s4CVv_wXL"
      },
      "source": [
        "## 2.3. 입출력 길이 제한과 요금에 영향을 미치는 \"토큰\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVOpklIZ_wXL"
      },
      "source": [
        "### 토큰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOB9wqqR_wXL",
        "outputId": "2631a09b-08b2-4a7f-b46b-6268dbac732c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken==0.7.0\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.7.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.7.0) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2025.1.31)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8bosMJc_wXM",
        "outputId": "cb0e6bc7-398c-46dc-ce48-3fe42d62729b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chat\n",
            "GPT\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"ChatGPT\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokens = encoding.encode(text)\n",
        "for token in tokens:\n",
        "    print(encoding.decode([token]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxH7dw_A_wXM"
      },
      "source": [
        "### 토크나이저와 tiktoken 소개\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmvxwnln_wXN",
        "outputId": "fdc6b359-8d29-4148-b82d-512603e28a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"LLM을 사용해 멋진 것을 만들기는 쉽지만, 프로덕션에서 사용할 수 있는 것을 만들기는 매우 어렵다.\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDkkgB2O_wXN"
      },
      "source": [
        "## 2.4. Chat Completions API 테스트 환경 준비\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw8zZmHt_wXN"
      },
      "source": [
        "### OpenAI API 키 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "flxI-7XP_wXN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npo3xLkw_wXO"
      },
      "source": [
        "## 2.5. Chat Completions API 실습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2HOmulr_wXO"
      },
      "source": [
        "### OpenAI 라이브러리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjrgcXOs_wXO"
      },
      "source": [
        "#### 【주의】알려진 오류에 관해\n",
        "\n",
        "openai 패키지가 의존하는 httpx의 업데이트로 인해, `openai==1.40.6`을 사용하는 부분에서 `TypeError: Client.__init__() got an unexpected keyword argument 'proxies'`라는 오류가 발생하게 되었습니다.\n",
        "\n",
        "이 오류는 `!pip install httpx==0.27.2`와 같이, httpx의 특정 버전을 설치함으로써 회피할 수 있습니다.\n",
        "\n",
        "또한, Google Colab에서 위 오류를 한 번 만난 후 `!pip install httpx==0.27.2`와 같이 패키지를 다시 설치한 경우, 다음 중 하나의 작업을 수행해야 합니다.\n",
        "\n",
        "- Google Colab의 \"런타임\"에서 \"세션 재시작하기\"를 실행합니다\n",
        "- \"런타임 연결 해제 및 삭제\"를 실행하여 패키지 설치부터 다시 시작합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsxTj0Sq_wXO",
        "outputId": "d4e716a7-8792-49fa-f265-f6cfea2492b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==1.40.6\n",
            "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (2.27.2)\n",
            "Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx, openai\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed httpx-0.27.2 openai-1.40.6\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.40.6 httpx==0.27.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypv2kgMf_wXO"
      },
      "source": [
        "### Chat Completions API 호출\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kcVjcsZ_wXO",
        "outputId": "683a09f0-5ad1-4c95-ec5d-afad9698ddf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9SHSJ0nLoPD5Ip9NkqlkSKg4Si13\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"안녕하세요, 존! 만나서 반갑습니다. 어떻게 도와드릴까요?\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741593362,\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_06737a9306\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 19,\n",
            "    \"prompt_tokens\": 25,\n",
            "    \"total_tokens\": 44,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"안녕하세요! 저는 존이라고 합니다!\"},\n",
        "    ],\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpKOi5EO_wXO"
      },
      "source": [
        "### 대화 이력을 고려한 응답 얻기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeDtazfV_wXP",
        "outputId": "06457161-3505-4b60-e8b2-c848e759daf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9SHSraEmdiQObBPk3s8bPnx3rEsK\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"네, 존 님이라고 하셨죠! 이름을 알고 있어요. 도움이 필요하시면 언제든지 말씀해 주세요.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741593362,\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_06737a9306\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 28,\n",
            "    \"prompt_tokens\": 63,\n",
            "    \"total_tokens\": 91,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"안녕하세요! 저는 존이라고 합니다!\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"안녕하세요, 존 님! 만나서 반갑습니다. 오늘은 어떤 이야기를 나눌까요?\"},\n",
        "        {\"role\": \"user\", \"content\": \"제 이름을 아시나요?\"},\n",
        "    ],\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqH8pWpA_wXP"
      },
      "source": [
        "### 스트리밍으로 응답 얻기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZMjlbY0_wXP",
        "outputId": "fdbb874a-01ff-432f-82ac-b0adf2415f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요, 존님! 어떻게 도와드릴까요?"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"안녕하세요! 저는 존이라고 합니다!\"},\n",
        "    ],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    content = chunk.choices[0].delta.content\n",
        "    if content is not None:\n",
        "        print(content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-78s5hY_wXP"
      },
      "source": [
        "### JSON 모드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M0_rQrC_wXP",
        "outputId": "94a5d9f5-f684-4b4a-bd22-34e7771562c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"people\": [\"할아버지\", \"할머니\"]}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '인물 목록을 다음 JSON 형식으로 출력해 주세요.\\n{\"people\": [\"aaa\", \"bbb\"]}',\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"옛날 옛적에 할아버지와 할머니가 살고 있었습니다\",\n",
        "        },\n",
        "    ],\n",
        "    response_format={\"type\": \"json_object\"},\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya1uakQK_wXP"
      },
      "source": [
        "### Vision(이미지 입력)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_jw56ye_wXP",
        "outputId": "141633c7-3689-4fff-c93b-c0af943b3527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "이미지는 책 표지로 보이며, 제목은 \"챗GPT와 랭체인을 활용한 LLM 기반 AI 앱 개발\"입니다. 디자인에는 다양한 그래픽 요소가 포함되어 있고, 주로 파란색과 노란색 계열의 색상이 사용된 것 같습니다. 중앙에는 여러 형태의 기하학적 모양과 곤충처럼 보이는 캐릭터가 배치되어 있습니다. 전반적으로 프로그래밍과 AI 개발에 관련된 내용을 다루고 있는 것으로 보입니다.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "image_url = \"https://raw.githubusercontent.com/ychoi-kr/langchain-book/main/cover.jpg\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"이미지를 설명해 주세요.\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8Af718X_wXP"
      },
      "source": [
        "### (칼럼) Completions API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7xUNK3f_wXQ",
        "outputId": "03ed0aaa-08de-4897-f1d5-d3ff98156c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-B9SHYJhpFCee52ckCtuZvaTIt92wZ\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"\\n반가워요, 저도 처음 만나서\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741593368,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct:20230824-v2\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 16,\n",
            "    \"prompt_tokens\": 17,\n",
            "    \"total_tokens\": 33\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=\"안녕하세요! 저는 존이라고 합니다!\",\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEi64HWF_wXQ"
      },
      "source": [
        "## 2.6. Function calling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAMY6Bzk_wXQ"
      },
      "source": [
        "### Function calling 샘플 코드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m16omLEV_wXQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    if \"seoul\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps(\n",
        "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
        "        )\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VJMYCfEp_wXQ"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-9wgEfM_wXQ",
        "outputId": "1ba2ed6d-7ab0-4523-af73-1d4f69c9d61f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9T2z45KQjB3M7JlIfg8a8F6BQiLy\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"tool_calls\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"tool_calls\": [\n",
            "          {\n",
            "            \"id\": \"call_VPAL6aDof51Hck9OOyKG6hKo\",\n",
            "            \"function\": {\n",
            "              \"arguments\": \"{\\\"location\\\":\\\"Seoul, KR\\\",\\\"unit\\\":\\\"celsius\\\"}\",\n",
            "              \"name\": \"get_current_weather\"\n",
            "            },\n",
            "            \"type\": \"function\"\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741596309,\n",
            "  \"model\": \"gpt-4o-2024-08-06\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_eb9dce56a8\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 24,\n",
            "    \"prompt_tokens\": 80,\n",
            "    \"total_tokens\": 104,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"서울 날씨는 어떤가요?\"},\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BK8heQpi_wXQ"
      },
      "outputs": [],
      "source": [
        "response_message = response.choices[0].message\n",
        "messages.append(response_message.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eubh561c_wXQ",
        "outputId": "ad8d0d60-67b7-4d69-f735-dbd1b4ee3f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"location\": \"Seoul\", \"temperature\": \"10\", \"unit\": \"celsius\"}\n"
          ]
        }
      ],
      "source": [
        "available_functions = {\n",
        "    \"get_current_weather\": get_current_weather,\n",
        "}\n",
        "\n",
        "# 사용하고 싶은 함수는 여러 개일 수 있으므로 반복문 사용\n",
        "for tool_call in response_message.tool_calls:\n",
        "    # 함수를 실행\n",
        "    function_name = tool_call.function.name\n",
        "    function_to_call = available_functions[function_name]\n",
        "    function_args = json.loads(tool_call.function.arguments)\n",
        "    function_response = function_to_call(\n",
        "        location=function_args.get(\"location\"),\n",
        "        unit=function_args.get(\"unit\"),\n",
        "    )\n",
        "    print(function_response)\n",
        "\n",
        "    # 함수 실행 결과를 대화 이력으로 messages에 추가\n",
        "    messages.append(\n",
        "        {\n",
        "            \"tool_call_id\": tool_call.id,\n",
        "            \"role\": \"tool\",\n",
        "            \"name\": function_name,\n",
        "            \"content\": function_response,\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mrhS_HQ_wXQ",
        "outputId": "f34b8324-b98c-4941-cb4d-2b80dffdda5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"서울 날씨는 어떤가요?\"\n",
            "  },\n",
            "  {\n",
            "    \"content\": null,\n",
            "    \"refusal\": null,\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "      {\n",
            "        \"id\": \"call_VPAL6aDof51Hck9OOyKG6hKo\",\n",
            "        \"function\": {\n",
            "          \"arguments\": \"{\\\"location\\\":\\\"Seoul, KR\\\",\\\"unit\\\":\\\"celsius\\\"}\",\n",
            "          \"name\": \"get_current_weather\"\n",
            "        },\n",
            "        \"type\": \"function\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"tool_call_id\": \"call_VPAL6aDof51Hck9OOyKG6hKo\",\n",
            "    \"role\": \"tool\",\n",
            "    \"name\": \"get_current_weather\",\n",
            "    \"content\": \"{\\\"location\\\": \\\"Seoul\\\", \\\"temperature\\\": \\\"10\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(json.dumps(messages, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfWL1yne_wXR",
        "outputId": "f1450a1c-6db6-4b03-9ea9-533def8a4444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9T30F1NsCNuPA2bt3s5BUFqk16Gf\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"현재 서울의 기온은 약 10도입니다. 더 구체적인 날씨 정보가 필요하시면 말씀해 주세요.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741596310,\n",
            "  \"model\": \"gpt-4o-2024-08-06\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_eb9dce56a8\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 28,\n",
            "    \"prompt_tokens\": 67,\n",
            "    \"total_tokens\": 95,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "second_response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        ")\n",
        "print(second_response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "n9JPO_tm_wXR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
