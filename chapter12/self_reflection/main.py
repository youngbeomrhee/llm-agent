# operator ëª¨ë“ˆ: ì—°ì‚°ì í•¨ìˆ˜ë¥¼ ì œê³µ (ì—¬ê¸°ì„œëŠ” addë¥¼ Annotated íƒ€ì…ì— ì‚¬ìš©)
import operator
# datetime ëª¨ë“ˆ: í˜„ì¬ ë‚ ì§œ/ì‹œê°„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì‚¬ìš©
from datetime import datetime
# typing ëª¨ë“ˆ: íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ Annotated(ë©”íƒ€ë°ì´í„° í¬í•¨ íƒ€ì…), Any(ëª¨ë“  íƒ€ì…) ì„í¬íŠ¸
from typing import Annotated, Any
# logging ëª¨ë“ˆ: í”„ë¡œê·¸ë¨ ì‹¤í–‰ íë¦„ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë¡œê¹… ê¸°ëŠ¥
import logging

# common ëª¨ë“ˆì—ì„œ Reflection ê´€ë ¨ í´ë˜ìŠ¤ë“¤ ì„í¬íŠ¸
# Reflection: ì„±ì°° ë°ì´í„° ëª¨ë¸, ReflectionManager: ì„±ì°° ë°ì´í„° ê´€ë¦¬, TaskReflector: ì„±ì°° ìˆ˜í–‰
from common.reflection_manager import Reflection, ReflectionManager, TaskReflector
# LangChain ì»¤ë®¤ë‹ˆí‹° ë„êµ¬: Tavily ê²€ìƒ‰ ì—”ì§„ì„ ì‚¬ìš©í•œ ì›¹ ê²€ìƒ‰ ë„êµ¬
from langchain_community.tools.tavily_search import TavilySearchResults
# LangChain ì¶œë ¥ íŒŒì„œ: LLM ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” íŒŒì„œ
from langchain_core.output_parsers import StrOutputParser
# LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í…œí”Œë¦¿ í´ë˜ìŠ¤
from langchain_core.prompts import ChatPromptTemplate
# OpenAIì˜ ChatGPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ LangChain ë˜í¼ í´ë˜ìŠ¤
from langchain_openai import ChatOpenAI
# LangGraph: ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤ë“¤
from langgraph.graph import END, StateGraph
# LangGraph ë¯¸ë¦¬ ë¹Œë“œëœ ì—ì´ì „íŠ¸: ReAct íŒ¨í„´ ì—ì´ì „íŠ¸ ìƒì„± í•¨ìˆ˜
from langgraph.prebuilt import create_react_agent
# passive_goal_creator ëª¨ë“ˆ: Goal ëª¨ë¸ê³¼ PassiveGoalCreator í´ë˜ìŠ¤ ì„í¬íŠ¸
from passive_goal_creator.main import Goal, PassiveGoalCreator
# prompt_optimizer ëª¨ë“ˆ: OptimizedGoal ëª¨ë¸ê³¼ PromptOptimizer í´ë˜ìŠ¤ ì„í¬íŠ¸
from prompt_optimizer.main import OptimizedGoal, PromptOptimizer
# Pydantic: ë°ì´í„° ê²€ì¦ ë° êµ¬ì¡°í™”ë¥¼ ìœ„í•œ BaseModelê³¼ Field ì„í¬íŠ¸
from pydantic import BaseModel, Field
# response_optimizer ëª¨ë“ˆ: ResponseOptimizer í´ë˜ìŠ¤ ì„í¬íŠ¸
from response_optimizer.main import ResponseOptimizer

# ë¡œê±° ì„¤ì •: ì´ ëª¨ë“ˆì˜ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
logger = logging.getLogger(__name__)


# format_reflections í•¨ìˆ˜: Reflection ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ XML í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…
# ê³¼ê±° ì„±ì°° ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©
def format_reflections(reflections: list[Reflection]) -> str:
    # ê° Reflectionì„ <ref_N> íƒœê·¸ë¡œ ê°ì‹¸ì„œ êµ¬ì¡°í™”
    # <task>ì™€ <reflection> íƒœê·¸ë¡œ ë‚´ìš©ì„ ëª…í™•íˆ êµ¬ë¶„
    return (
        "\n\n".join(
            f"<ref_{i}><task>{r.task}</task><reflection>{r.reflection}</reflection></ref_{i}>"
            for i, r in enumerate(reflections)
        )
        if reflections  # ì„±ì°°ì´ ìˆìœ¼ë©´ í¬ë§·íŒ…ëœ ë¬¸ìì—´ ë°˜í™˜
        else "No relevant past reflections."  # ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€
    )


# DecomposedTasks í´ë˜ìŠ¤: ë¶„í•´ëœ íƒœìŠ¤í¬ë“¤ì„ ë‹´ëŠ” ì»¨í…Œì´ë„ˆ
# Self Reflectionì—ì„œëŠ” 3~5ê°œì˜ íƒœìŠ¤í¬ë¡œ ë¶„í•´
class DecomposedTasks(BaseModel):
    # values í•„ë“œ: íƒœìŠ¤í¬ ë¬¸ìì—´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
    # min_items=3, max_items=5: 3~5ê°œì˜ íƒœìŠ¤í¬ë¡œ ë¶„í•´í•˜ë„ë¡ ì œì•½
    values: list[str] = Field(
        default_factory=list,
        min_items=3,
        max_items=5,
        description="3~5ê°œë¡œ ë¶„í•´ëœ íƒœìŠ¤í¬",
    )


# ReflectiveAgentState í´ë˜ìŠ¤: Self Reflection ì›Œí¬í”Œë¡œìš°ì˜ ìƒíƒœ ê´€ë¦¬
# ì¼ë°˜ Stateì™€ ë‹¬ë¦¬ reflection_idsì™€ retry_count í•„ë“œê°€ ì¶”ê°€ë¨
class ReflectiveAgentState(BaseModel):
    # query í•„ë“œ: ì‚¬ìš©ìê°€ ìµœì´ˆì— ì…ë ¥í•œ ì¿¼ë¦¬
    query: str = Field(..., description="ì‚¬ìš©ìê°€ ì²˜ìŒì— ì…ë ¥í•œ ì¿¼ë¦¬")
    # optimized_goal í•„ë“œ: SMART ì›ì¹™ìœ¼ë¡œ ìµœì í™”ëœ ëª©í‘œ
    optimized_goal: str = Field(default="", description="ìµœì í™”ëœ ëª©í‘œ")
    # optimized_response í•„ë“œ: ìµœì¢… ì‘ë‹µì˜ í˜•ì‹ê³¼ êµ¬ì¡°ì— ëŒ€í•œ ì •ì˜
    optimized_response: str = Field(
        default="", description="ìµœì í™”ëœ ì‘ë‹µ ì •ì˜"
    )
    # tasks í•„ë“œ: ë¶„í•´ëœ íƒœìŠ¤í¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
    tasks: list[str] = Field(default_factory=list, description="ì‹¤í–‰í•  íƒœìŠ¤í¬ ëª©ë¡")
    # current_task_index í•„ë“œ: í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ì˜ ì¸ë±ìŠ¤
    current_task_index: int = Field(default=0, description="í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ ë²ˆí˜¸")
    # results í•„ë“œ: ê° íƒœìŠ¤í¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
    results: Annotated[list[str], operator.add] = Field(
        default_factory=list, description="ì‹¤í–‰ ì™„ë£Œëœ íƒœìŠ¤í¬ ê²°ê³¼ ëª©ë¡"
    )
    # reflection_ids í•„ë“œ: ê° íƒœìŠ¤í¬ì˜ ì„±ì°° ê²°ê³¼ IDë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸
    # Self Reflectionì˜ í•µì‹¬: ê° ì‹¤í–‰ë§ˆë‹¤ ì„±ì°°ì„ ìˆ˜í–‰í•˜ê³  IDë¥¼ ê¸°ë¡
    reflection_ids: Annotated[list[str], operator.add] = Field(
        default_factory=list, description="ë¦¬í”Œë ‰ì…˜ ê²°ê³¼ì˜ ID ëª©ë¡"
    )
    # final_output í•„ë“œ: ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ í›„ ì§‘ê³„ëœ ìµœì¢… ì¶œë ¥
    final_output: str = Field(default="", description="ìµœì¢… ì¶œë ¥ ê²°ê³¼")
    # retry_count í•„ë“œ: í˜„ì¬ íƒœìŠ¤í¬ì˜ ì¬ì‹œë„ íšŸìˆ˜
    # ì„±ì°° ê²°ê³¼ ì¬ì‹œë„ê°€ í•„ìš”í•˜ë©´ ì¦ê°€, í†µê³¼í•˜ë©´ 0ìœ¼ë¡œ ë¦¬ì…‹
    retry_count: int = Field(default=0, description="íƒœìŠ¤í¬ ì¬ì‹œë„ íšŸìˆ˜")


class ReflectiveGoalCreator:
    def __init__(self, llm: ChatOpenAI, reflection_manager: ReflectionManager):
        self.llm = llm
        self.reflection_manager = reflection_manager
        self.passive_goal_creator = PassiveGoalCreator(llm=self.llm)
        self.prompt_optimizer = PromptOptimizer(llm=self.llm)

    def run(self, query: str) -> str:
        logger.info("ğŸ¯ [ëª©í‘œ ì„¤ì •] ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•œ ëª©í‘œ ìƒì„± ì‹œì‘")
        relevant_reflections = self.reflection_manager.get_relevant_reflections(query)
        logger.info(f"  ê´€ë ¨ ê³¼ê±° íšŒê³  {len(relevant_reflections)}ê°œ ë°œê²¬")
        reflection_text = format_reflections(relevant_reflections)

        query = f"{query}\n\nëª©í‘œ ì„¤ì • ì‹œ ë‹¤ìŒì˜ ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•  ê²ƒ:\n{reflection_text}"
        goal: Goal = self.passive_goal_creator.run(query=query)
        logger.info(f"  ê¸°ë³¸ ëª©í‘œ ìƒì„± ì™„ë£Œ: {goal.text[:100]}...")
        optimized_goal: OptimizedGoal = self.prompt_optimizer.run(query=goal.text)
        logger.info(f"  ëª©í‘œ ìµœì í™” ì™„ë£Œ")
        return optimized_goal.text


class ReflectiveResponseOptimizer:
    def __init__(self, llm: ChatOpenAI, reflection_manager: ReflectionManager):
        self.llm = llm
        self.reflection_manager = reflection_manager
        self.response_optimizer = ResponseOptimizer(llm=llm)

    def run(self, query: str) -> str:
        logger.info("ğŸ“ [ì‘ë‹µ ìµœì í™”] ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•œ ì‘ë‹µ í˜•ì‹ ì •ì˜ ì‹œì‘")
        relevant_reflections = self.reflection_manager.get_relevant_reflections(query)
        logger.info(f"  ê´€ë ¨ ê³¼ê±° íšŒê³  {len(relevant_reflections)}ê°œ ë°œê²¬")
        reflection_text = format_reflections(relevant_reflections)

        query = f"{query}\n\nì‘ë‹µ ìµœì í™”ì— ë‹¤ìŒì˜ ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•  ê²ƒ:\n{reflection_text}"
        optimized_response: str = self.response_optimizer.run(query=query)
        logger.info("  ì‘ë‹µ í˜•ì‹ ì •ì˜ ì™„ë£Œ")
        return optimized_response


class QueryDecomposer:
    def __init__(self, llm: ChatOpenAI, reflection_manager: ReflectionManager):
        self.llm = llm.with_structured_output(DecomposedTasks)
        self.current_date = datetime.now().strftime("%Y-%m-%d")
        self.reflection_manager = reflection_manager

    def run(self, query: str) -> DecomposedTasks:
        logger.info("ğŸ“‹ [ëª©í‘œ ë¶„í•´] ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•œ íƒœìŠ¤í¬ ë¶„í•´ ì‹œì‘")
        relevant_reflections = self.reflection_manager.get_relevant_reflections(query)
        logger.info(f"  ê´€ë ¨ ê³¼ê±° íšŒê³  {len(relevant_reflections)}ê°œ ë°œê²¬")
        reflection_text = format_reflections(relevant_reflections)
        prompt = ChatPromptTemplate.from_template(
            f"CURRENT_DATE: {self.current_date}\n"
            "-----\n"
            "íƒœìŠ¤í¬: ì£¼ì–´ì§„ ëª©í‘œë¥¼ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ íƒœìŠ¤í¬ë¡œ ë¶„í•´í•´ ì£¼ì„¸ìš”.\n"
            "ìš”ê±´:\n"
            "1. ë‹¤ìŒ í–‰ë™ë§Œìœ¼ë¡œ ëª©í‘œë¥¼ ë‹¬ì„±í•  ê²ƒ. ì ˆëŒ€ ì§€ì •ëœ ê²ƒ ì™¸ì˜ í–‰ë™ì„ ì·¨í•˜ì§€ ë§ ê²ƒ.\n"
            "   - ì¸í„°ë„·ì„ ì´ìš©í•˜ì—¬ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•œë‹¤.\n"
            "2. ê° íƒœìŠ¤í¬ëŠ” êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±ë˜ì–´ ìˆìœ¼ë©°, ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ë° ê²€ì¦ ê°€ëŠ¥í•œ ì •ë³´ë¥¼ í¬í•¨í•  ê²ƒ. ì¶”ìƒì ì¸ í‘œí˜„ì„ ì „í˜€ í¬í•¨í•˜ì§€ ì•Šì„ ê²ƒ.\n"
            "3. íƒœìŠ¤í¬ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ìˆœì„œë¡œ ë‚˜ì—´í•  ê²ƒ.\n"
            "4. íƒœìŠ¤í¬ëŠ” í•œêµ­ì–´ë¡œ ì¶œë ¥í•  ê²ƒ.\n"
            "5. íƒœìŠ¤í¬ë¥¼ ì‘ì„±í•  ë•Œ ë‹¤ìŒì˜ ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•  ê²ƒ:\n{reflections}\n\n"
            "ëª©í‘œ: {query}"
        )
        chain = prompt | self.llm
        tasks = chain.invoke({"query": query, "reflections": reflection_text})
        logger.info(f"  íƒœìŠ¤í¬ ë¶„í•´ ì™„ë£Œ: ì´ {len(tasks.values)}ê°œì˜ íƒœìŠ¤í¬ ìƒì„±")
        for i, task in enumerate(tasks.values, 1):
            logger.info(f"    íƒœìŠ¤í¬ {i}: {task[:80]}...")
        return tasks


class TaskExecutor:
    def __init__(self, llm: ChatOpenAI, reflection_manager: ReflectionManager):
        self.llm = llm
        self.reflection_manager = reflection_manager
        self.current_date = datetime.now().strftime("%Y-%m-%d")
        self.tools = [TavilySearchResults(max_results=3)]

    def run(self, task: str) -> str:
        logger.info(f"âš™ï¸  [íƒœìŠ¤í¬ ì‹¤í–‰] ì‹œì‘: {task[:80]}...")
        relevant_reflections = self.reflection_manager.get_relevant_reflections(task)
        logger.info(f"  ê´€ë ¨ ê³¼ê±° íšŒê³  {len(relevant_reflections)}ê°œ ì ìš©")
        reflection_text = format_reflections(relevant_reflections)
        agent = create_react_agent(self.llm, self.tools)
        result = agent.invoke(
            {
                "messages": [
                    (
                        "human",
                        f"CURRENT_DATE: {self.current_date}\n"
                        "-----\n"
                        f"ë‹¤ìŒ íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n\níƒœìŠ¤í¬: {task}\n\n"
                        "ìš”ê±´:\n"
                        "1. í•„ìš”ì— ë”°ë¼ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ê²ƒ.\n"
                        "2. ì‹¤í–‰ ì‹œ ì² ì €í•˜ê³  í¬ê´„ì ì¼ ê²ƒ.\n"
                        "3. ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ì‚¬ì‹¤ê³¼ ë°ì´í„°ë¥¼ ì œê³µí•  ê²ƒ.\n"
                        "4. ë°œê²¬ ì‚¬í•­ì„ ëª…í™•í•˜ê²Œ ìš”ì•½í•  ê²ƒ.\n"
                        f"5. ë‹¤ìŒì˜ ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•  ê²ƒ:\n{reflection_text}\n",
                    )
                ]
            }
        )
        content = result["messages"][-1].content
        logger.info(f"  íƒœìŠ¤í¬ ì‹¤í–‰ ì™„ë£Œ (ê²°ê³¼ ê¸¸ì´: {len(content)} ê¸€ì)")
        return content


class ResultAggregator:
    def __init__(self, llm: ChatOpenAI, reflection_manager: ReflectionManager):
        self.llm = llm
        self.reflection_manager = reflection_manager
        self.current_date = datetime.now().strftime("%Y-%m-%d")

    def run(
        self,
        query: str,
        results: list[str],
        reflection_ids: list[str],
        response_definition: str,
    ) -> str:
        logger.info("ğŸ“Š [ê²°ê³¼ ì§‘ê³„] ê³¼ê±° íšŒê³ ë¥¼ ë°˜ì˜í•œ ìµœì¢… ê²°ê³¼ ìƒì„± ì‹œì‘")
        logger.info(f"  ìˆ˜ì§‘ëœ ê²°ê³¼ ê°œìˆ˜: {len(results)}ê°œ")
        logger.info(f"  ì°¸ì¡°í•  íšŒê³  ê°œìˆ˜: {len(reflection_ids)}ê°œ")
        relevant_reflections = [
            self.reflection_manager.get_reflection(rid) for rid in reflection_ids
        ]
        prompt = ChatPromptTemplate.from_template(
            "ì£¼ì–´ì§„ ëª©í‘œ:\n{query}\n\n"
            "ì¡°ì‚¬ ê²°ê³¼:\n{results}\n\n"
            "ì£¼ì–´ì§„ ëª©í‘œì— ëŒ€í•´ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ìŒ ì§€ì‹œì— ê¸°ë°˜í•œ ì‘ë‹µì„ ìƒì„±í•´ ì£¼ì„¸ìš”.\n"
            "{response_definition}\n\n"
            "ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•  ê²ƒ:\n{reflection_text}\n"
        )
        chain = prompt | self.llm | StrOutputParser()
        final_output = chain.invoke(
            {
                "query": query,
                "results": "\n\n".join(
                    f"ì •ë³´ {i+1}:\n{result}" for i, result in enumerate(results)
                ),
                "response_definition": response_definition,
                "reflection_text": format_reflections(relevant_reflections),
            }
        )
        logger.info(f"  ê²°ê³¼ ì§‘ê³„ ì™„ë£Œ (ìµœì¢… ê²°ê³¼ ê¸¸ì´: {len(final_output)} ê¸€ì)")
        return final_output


class ReflectiveAgent:
    def __init__(
        self,
        llm: ChatOpenAI,
        reflection_manager: ReflectionManager,
        task_reflector: TaskReflector,
        max_retries: int = 2,
    ):
        self.reflection_manager = reflection_manager
        self.task_reflector = task_reflector
        self.reflective_goal_creator = ReflectiveGoalCreator(
            llm=llm, reflection_manager=self.reflection_manager
        )
        self.reflective_response_optimizer = ReflectiveResponseOptimizer(
            llm=llm, reflection_manager=self.reflection_manager
        )
        self.query_decomposer = QueryDecomposer(
            llm=llm, reflection_manager=self.reflection_manager
        )
        self.task_executor = TaskExecutor(
            llm=llm, reflection_manager=self.reflection_manager
        )
        self.result_aggregator = ResultAggregator(
            llm=llm, reflection_manager=self.reflection_manager
        )
        self.max_retries = max_retries
        self.graph = self._create_graph()

    def _create_graph(self) -> StateGraph:
        graph = StateGraph(ReflectiveAgentState)
        graph.add_node("goal_setting", self._goal_setting)
        graph.add_node("decompose_query", self._decompose_query)
        graph.add_node("execute_task", self._execute_task)
        graph.add_node("reflect_on_task", self._reflect_on_task)
        graph.add_node("update_task_index", self._update_task_index)
        graph.add_node("aggregate_results", self._aggregate_results)
        graph.set_entry_point("goal_setting")
        graph.add_edge("goal_setting", "decompose_query")
        graph.add_edge("decompose_query", "execute_task")
        graph.add_edge("execute_task", "reflect_on_task")
        graph.add_conditional_edges(
            "reflect_on_task",
            self._should_retry_or_continue,
            {
                "retry": "execute_task",
                "continue": "update_task_index",
                "finish": "aggregate_results",
            },
        )
        graph.add_edge("update_task_index", "execute_task")
        graph.add_edge("aggregate_results", END)
        return graph.compile()

    def _goal_setting(self, state: ReflectiveAgentState) -> dict[str, Any]:
        logger.info("=" * 80)
        logger.info("ğŸ¯ [1ë‹¨ê³„: ëª©í‘œ ì„¤ì •] ì‹œì‘")
        logger.info("=" * 80)
        optimized_goal: str = self.reflective_goal_creator.run(query=state.query)
        optimized_response: str = self.reflective_response_optimizer.run(
            query=optimized_goal
        )
        logger.info("âœ… [1ë‹¨ê³„: ëª©í‘œ ì„¤ì •] ì™„ë£Œ\n")
        return {
            "optimized_goal": optimized_goal,
            "optimized_response": optimized_response,
        }

    def _decompose_query(self, state: ReflectiveAgentState) -> dict[str, Any]:
        logger.info("=" * 80)
        logger.info("ğŸ“‹ [2ë‹¨ê³„: ëª©í‘œ ë¶„í•´] ì‹œì‘")
        logger.info("=" * 80)
        tasks: DecomposedTasks = self.query_decomposer.run(query=state.optimized_goal)
        logger.info("âœ… [2ë‹¨ê³„: ëª©í‘œ ë¶„í•´] ì™„ë£Œ\n")
        return {"tasks": tasks.values}

    def _execute_task(self, state: ReflectiveAgentState) -> dict[str, Any]:
        current_task_num = state.current_task_index + 1
        total_tasks = len(state.tasks)
        if state.retry_count > 0:
            logger.info(f"ğŸ”„ [ì¬ì‹œë„ {state.retry_count}íšŒì°¨] íƒœìŠ¤í¬ {current_task_num}/{total_tasks} ì¬ì‹¤í–‰")
        else:
            logger.info(f"ğŸ“ [3ë‹¨ê³„: íƒœìŠ¤í¬ ì‹¤í–‰] íƒœìŠ¤í¬ {current_task_num}/{total_tasks} ì‹¤í–‰")
        current_task = state.tasks[state.current_task_index]
        result = self.task_executor.run(task=current_task)
        return {"results": [result], "current_task_index": state.current_task_index}

    def _reflect_on_task(self, state: ReflectiveAgentState) -> dict[str, Any]:
        logger.info(f"ğŸ” [ìê¸° ì„±ì°°] íƒœìŠ¤í¬ {state.current_task_index + 1} ê²°ê³¼ ê²€í†  ì¤‘...")
        current_task = state.tasks[state.current_task_index]
        current_result = state.results[-1]
        reflection = self.task_reflector.run(task=current_task, result=current_result)

        if reflection.judgment.needs_retry:
            logger.info(f"  âš ï¸  ì¬ì‹œë„ í•„ìš”: {', '.join(reflection.judgment.reasons)}")
        else:
            logger.info(f"  âœ… ì„±ì°° í†µê³¼")

        logger.info(f"  ì„±ì°° ë‚´ìš©: {reflection.reflection[:100]}...\n")

        return {
            "reflection_ids": [reflection.id],
            "retry_count": (
                state.retry_count + 1 if reflection.judgment.needs_retry else 0
            ),
        }

    def _should_retry_or_continue(self, state: ReflectiveAgentState) -> str:
        latest_reflection_id = state.reflection_ids[-1]
        latest_reflection = self.reflection_manager.get_reflection(latest_reflection_id)
        if (
            latest_reflection
            and latest_reflection.judgment.needs_retry
            and state.retry_count < self.max_retries
        ):
            logger.info(f"â†©ï¸  ì¬ì‹œë„ ê²°ì •: í˜„ì¬ ì¬ì‹œë„ íšŸìˆ˜ {state.retry_count}/{self.max_retries}")
            return "retry"
        elif state.current_task_index < len(state.tasks) - 1:
            logger.info("â¡ï¸  ë‹¤ìŒ íƒœìŠ¤í¬ë¡œ ì§„í–‰")
            return "continue"
        else:
            logger.info("âœ… ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ\n")
            return "finish"

    def _update_task_index(self, state: ReflectiveAgentState) -> dict[str, Any]:
        logger.info(f"ğŸ“Œ íƒœìŠ¤í¬ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸: {state.current_task_index} â†’ {state.current_task_index + 1}\n")
        return {"current_task_index": state.current_task_index + 1}

    def _aggregate_results(self, state: ReflectiveAgentState) -> dict[str, Any]:
        logger.info("=" * 80)
        logger.info("ğŸ“Š [4ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„] ì‹œì‘")
        logger.info("=" * 80)
        final_output = self.result_aggregator.run(
            query=state.optimized_goal,
            results=state.results,
            reflection_ids=state.reflection_ids,
            response_definition=state.optimized_response,
        )
        logger.info("âœ… [4ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„] ì™„ë£Œ\n")
        return {"final_output": final_output}

    def run(self, query: str) -> str:
        logger.info("=" * 80)
        logger.info("ğŸ¬ Self-Reflection Agent ì‹œì‘")
        logger.info("=" * 80)
        logger.info(f"ì‚¬ìš©ì ì¿¼ë¦¬: {query}\n")
        initial_state = ReflectiveAgentState(query=query)
        final_state = self.graph.invoke(initial_state, {"recursion_limit": 1000})
        logger.info("=" * 80)
        logger.info("ğŸ‰ Self-Reflection Agent ì™„ë£Œ")
        logger.info("=" * 80)
        return final_state.get("final_output", "ì˜¤ë¥˜: ì¶œë ¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


# main í•¨ìˆ˜: Self-reflection íŒ¨í„´ì„ êµ¬í˜„í•˜ëŠ” ì§„ì…ì 
# Self-reflection: ì—ì´ì „íŠ¸ê°€ ìì‹ ì˜ ìˆ˜í–‰ ê²°ê³¼ë¥¼ ëŒì•„ë³´ê³  ê°œì„ í•˜ëŠ” íŒ¨í„´
def main():
    # argparse ëª¨ë“ˆ: ì»¤ë§¨ë“œ ë¼ì¸ ì¸ìë¥¼ íŒŒì‹±í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸
    import argparse

    # settings ëª¨ë“ˆì—ì„œ Settings í´ë˜ìŠ¤ ì„í¬íŠ¸
    from settings import Settings

    # Settings ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    settings = Settings()

    # ë¡œê¹… ì„¤ì •: INFO ë ˆë²¨ ì´ìƒì˜ ë¡œê·¸ë¥¼ ì½˜ì†”ì— ì¶œë ¥
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s',  # ë©”ì‹œì§€ë§Œ ì¶œë ¥ (ì‹œê°„, ë ˆë²¨ ë“± ì œì™¸)
        handlers=[logging.StreamHandler()]
    )

    # ArgumentParser ìƒì„±
    parser = argparse.ArgumentParser(
        # Self-reflection ë°©ì‹ìœ¼ë¡œ íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•œë‹¤ëŠ” ì„¤ëª…
        description="ReflectiveAgentë¥¼ ì‚¬ìš©í•´ íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤(Self-reflection)"
    )
    # --task ì¸ì ì¶”ê°€
    parser.add_argument("--task", type=str, required=True, help="ì‹¤í–‰í•  íƒœìŠ¤í¬")
    # ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì íŒŒì‹±
    args = parser.parse_args()

    # ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    llm = ChatOpenAI(
        model=settings.openai_smart_model, temperature=settings.temperature
    )
    # ReflectionManager ì´ˆê¸°í™”: ë¦¬í”Œë ‰ì…˜ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì €ì¥í•˜ê³  ê´€ë¦¬
    # file_path: Self-reflection ë°ì´í„°ë¥¼ ì €ì¥í•  JSON íŒŒì¼ ê²½ë¡œ
    reflection_manager = ReflectionManager(file_path="tmp/self_reflection_db.json")
    # TaskReflector ì´ˆê¸°í™”: íƒœìŠ¤í¬ ìˆ˜í–‰ í›„ ë¦¬í”Œë ‰ì…˜ì„ ìˆ˜í–‰í•˜ëŠ” ì—­í• 
    # ê°™ì€ LLMì„ ì‚¬ìš©í•˜ì—¬ ìê¸° ì„±ì°° (Self-reflection)
    task_reflector = TaskReflector(llm=llm, reflection_manager=reflection_manager)
    # ReflectiveAgent ì´ˆê¸°í™”: ìê¸° ì„±ì°° ê¸°ëŠ¥ì„ ê°€ì§„ ì—ì´ì „íŠ¸ ìƒì„±
    agent = ReflectiveAgent(
        llm=llm, reflection_manager=reflection_manager, task_reflector=task_reflector
    )
    # íƒœìŠ¤í¬ ì‹¤í–‰: ìˆ˜í–‰ â†’ ì„±ì°° â†’ í•„ìš”ì‹œ ì¬ì‹œë„ì˜ ë°˜ë³µì  í”„ë¡œì„¸ìŠ¤
    result = agent.run(args.task)
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(result)


# ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ main() í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
if __name__ == "__main__":
    main()
