# Cross-Reflection ìƒì„¸ íë¦„ ê°€ì´ë“œ

## ê°œìš”

Cross-Reflectionì€ **ë‘ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ LLM ì œê³µì**ë¥¼ í™œìš©í•˜ì—¬ ìƒí˜¸ ê²€ì¦ê³¼ í’ˆì§ˆ ê°œì„ ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ ë””ìì¸ íŒ¨í„´ì…ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•
- **ì´ì¤‘ LLM êµ¬ì¡°**: OpenAI LLMì´ ì‹¤í–‰, Anthropic LLMì´ ì„±ì°°
- **êµì°¨ ê²€ì¦**: ë‹¤ë¥¸ ëª¨ë¸ì˜ ê´€ì ì—ì„œ ê²°ê³¼ë¥¼ í‰ê°€
- **í¸í–¥ ê°ì†Œ**: ë‹¨ì¼ ëª¨ë¸ì˜ í•œê³„ë¥¼ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë³´ì™„
- **Self-Reflection ì¸í”„ë¼ ì¬ì‚¬ìš©**: ReflectiveAgentë¥¼ ê·¸ëŒ€ë¡œ í™œìš©

---

## Cross-Reflection vs Self-Reflection

### ë¹„êµí‘œ

| ë¹„êµ í•­ëª© | Self-Reflection | Cross-Reflection |
|----------|----------------|------------------|
| **ì‹¤í–‰ LLM** | OpenAI | OpenAI |
| **ì„±ì°° LLM** | OpenAI (ë™ì¼) | Anthropic (ë‹¤ë¦„) |
| **ì¥ì ** | êµ¬í˜„ ë‹¨ìˆœ, ë¹„ìš© íš¨ìœ¨ì  | ë‹¤ê°ë„ ê²€ì¦, í¸í–¥ ê°ì†Œ |
| **ë‹¨ì ** | ìê¸° í¸í–¥ ê°€ëŠ¥ì„± | ë¹„ìš© ì¦ê°€, ë³µì¡ë„ ì¦ê°€ |
| **ì í•©í•œ ê²½ìš°** | ì¼ë°˜ì ì¸ í’ˆì§ˆ ê´€ë¦¬ | ì¤‘ìš”í•œ ì˜ì‚¬ê²°ì •, ë†’ì€ ì‹ ë¢°ë„ ìš”êµ¬ |

### ì™œ Cross-Reflectionì´ í•„ìš”í•œê°€?

#### ë¬¸ì œ: Self-Reflectionì˜ í•œê³„

```python
# Self-Reflection
openai_llm = ChatOpenAI(model="gpt-4")
reflector = TaskReflector(llm=openai_llm)  # ê°™ì€ ëª¨ë¸

# ë¬¸ì œì :
# 1. ìê¸° ì •ë‹¹í™”: ê°™ì€ ëª¨ë¸ì´ ìì‹ ì˜ íŒë‹¨ì„ í‰ê°€
# 2. ì¼ê´€ëœ í¸í–¥: ëª¨ë¸ì˜ ê³ ìœ í•œ í¸í–¥ì´ ì‹¤í–‰ê³¼ ì„±ì°° ëª¨ë‘ì— ì˜í–¥
# 3. ë§¹ì  ê°„ê³¼: ëª¨ë¸ì´ ì¸ì§€í•˜ì§€ ëª»í•˜ëŠ” ì‹¤ìˆ˜ë¥¼ ë°œê²¬í•˜ê¸° ì–´ë ¤ì›€
```

#### í•´ê²°ì±…: Cross-Reflection

```python
# Cross-Reflection
openai_llm = ChatOpenAI(model="gpt-4")         # ì‹¤í–‰ìš©
anthropic_llm = ChatAnthropic(model="claude")  # ì„±ì°°ìš©
reflector = TaskReflector(llm=anthropic_llm)   # ë‹¤ë¥¸ ëª¨ë¸

# ì¥ì :
# 1. ë…ë¦½ì  í‰ê°€: Anthropicì´ OpenAIì˜ ê²°ê³¼ë¥¼ ê°ê´€ì ìœ¼ë¡œ í‰ê°€
# 2. ìƒí˜¸ ë³´ì™„: OpenAIì˜ ì•½ì ì„ Anthropicì´ ë°œê²¬ ê°€ëŠ¥
# 3. ë‹¤ê°ë„ ë¶„ì„: ë‹¤ë¥¸ í•™ìŠµ ë°ì´í„°ì™€ ì•„í‚¤í…ì²˜ë¡œ ë‹¤ì–‘í•œ ê´€ì  ì œê³µ
```

### ì‹¤ì œ ì‚¬ë¡€: ì½”ë“œ ë¦¬ë·°

#### Self-Reflectionì˜ ë¬¸ì œì 

```
ì‚¬ìš©ì: "Pythonìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ êµ¬í˜„"

OpenAI ì‹¤í–‰:
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

OpenAI ì„±ì°°:
âœ… ì¬ê·€ë¡œ í”¼ë³´ë‚˜ì¹˜ë¥¼ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„í•¨
âœ… ë² ì´ìŠ¤ ì¼€ì´ìŠ¤ê°€ ì •í™•í•¨
â†’ ì¬ì‹œë„ ë¶ˆí•„ìš”

ë¬¸ì œ: ë™ì¼ ëª¨ë¸ì´ë¼ ì„±ëŠ¥ ë¬¸ì œ(O(2^n))ë¥¼ ë†“ì¹¨
```

#### Cross-Reflectionì˜ íš¨ê³¼

```
ì‚¬ìš©ì: "Pythonìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ êµ¬í˜„"

OpenAI ì‹¤í–‰:
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

Anthropic ì„±ì°°:
âš ï¸ ì¬ì‹œë„ í•„ìš”
ì´ìœ :
- ì¬ê·€ êµ¬í˜„ì€ ì •í™•í•˜ì§€ë§Œ íš¨ìœ¨ì„±ì´ ë§¤ìš° ë‚®ìŒ (O(2^n))
- nì´ í° ê²½ìš° ì‹¬ê°í•œ ì„±ëŠ¥ ë¬¸ì œ ë°œìƒ
- ë©”ëª¨ì´ì œì´ì…˜ ë˜ëŠ” ë°˜ë³µë¬¸ ì‚¬ìš© ê¶Œì¥

â†’ ì¬ì‹œë„ ìš”ì²­

OpenAI ì¬ì‹¤í–‰:
def fibonacci(n):
    if n <= 1:
        return n
    memo = [0, 1]
    for i in range(2, n + 1):
        memo.append(memo[i-1] + memo[i-2])
    return memo[n]

Anthropic ì¬ì„±ì°°:
âœ… O(n) ì‹œê°„ ë³µì¡ë„ë¡œ ê°œì„ ë¨
âœ… í° ì…ë ¥ê°’ì—ë„ íš¨ìœ¨ì ìœ¼ë¡œ ë™ì‘
â†’ í†µê³¼
```

---

## ì›Œí¬í”Œë¡œìš° ì „ì²´ êµ¬ì¡°

### ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    Start([ì‚¬ìš©ì ì¿¼ë¦¬]) --> Init[LLM ì´ˆê¸°í™”]

    Init --> OpenAI[OpenAI LLM<br/>gpt-4<br/>ì‹¤í–‰ ë‹´ë‹¹]
    Init --> Anthropic[Anthropic LLM<br/>claude<br/>ì„±ì°° ë‹´ë‹¹]

    OpenAI --> Step1[1ë‹¨ê³„: ëª©í‘œ ì„¤ì •<br/>goal_setting]
    Anthropic -.-> Step1

    Step1 --> Step2[2ë‹¨ê³„: ëª©í‘œ ë¶„í•´<br/>decompose_query]
    Step2 --> Step3[3ë‹¨ê³„: íƒœìŠ¤í¬ ì‹¤í–‰<br/>execute_task]

    Step3 --> Exec[OpenAIê°€ íƒœìŠ¤í¬ ìˆ˜í–‰]
    Exec --> Reflect[4ë‹¨ê³„: ì„±ì°°<br/>reflect_on_task]

    Reflect --> AnthropicCheck[Anthropicì´ ê²°ê³¼ í‰ê°€]

    AnthropicCheck -->|ì¬ì‹œë„ í•„ìš”<br/>retry_count < max_retries| Step3
    AnthropicCheck -->|í†µê³¼| CheckMore{ë” ë§ì€<br/>íƒœìŠ¤í¬?}

    CheckMore -->|Yes| Step3
    CheckMore -->|No| Step5[5ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„<br/>aggregate_results]

    Step5 --> End([ìµœì¢… ê²°ê³¼])

    style OpenAI fill:#d4edda,stroke:#28a745,stroke-width:3px
    style Anthropic fill:#d1ecf1,stroke:#17a2b8,stroke-width:3px
    style Exec fill:#d4edda
    style AnthropicCheck fill:#d1ecf1
    style Reflect fill:#fff3cd
    style Step1 fill:#e1f5ff
    style Step2 fill:#fff4e1
    style Step3 fill:#ffe1f5
    style Step5 fill:#e1ffe1
    style Start fill:#f0f0f0
    style End fill:#f0f0f0
```

**ì½”ë“œ ì°¸ì¡°:** [cross_reflection/main.py](main.py), [self_reflection/main.py](../self_reflection/main.py)

---

## ì½”ë“œ êµ¬ì¡°

### Cross-Reflectionì˜ í•µì‹¬ ì°¨ì´ì 

**ì½”ë“œ ì°¸ì¡°:** [main.py#L52-L86](main.py#L52-L86)

```python
# OpenAI LLM ì´ˆê¸°í™”: ì£¼ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ìš© ëª¨ë¸
openai_llm = ChatOpenAI(
    model=settings.openai_smart_model,
    temperature=settings.temperature
)

# Anthropic LLM ì´ˆê¸°í™”: ë¦¬í”Œë ‰ì…˜(ì„±ì°°)ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸
# Cross-reflectionì˜ í•µì‹¬: ë‹¤ë¥¸ ì œê³µìì˜ LLMì„ ì‚¬ìš©í•˜ì—¬ êµì°¨ ê²€ì¦
anthropic_llm = ChatAnthropic(
    model=settings.anthropic_smart_model,
    temperature=settings.temperature
)

# ReflectionManager ì´ˆê¸°í™”
reflection_manager = ReflectionManager(file_path="tmp/cross_reflection_db.json")

# Anthropic LLMì„ ì‚¬ìš©í•˜ëŠ” TaskReflector ì´ˆê¸°í™”
# Anthropic ëª¨ë¸ì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ OpenAI ëª¨ë¸ê³¼ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì„±ì°° ê°€ëŠ¥
anthropic_task_reflector = TaskReflector(
    llm=anthropic_llm,  # â­ Anthropic LLM ì‚¬ìš©
    reflection_manager=reflection_manager
)

# ReflectiveAgent ì´ˆê¸°í™”
agent = ReflectiveAgent(
    llm=openai_llm,  # â­ OpenAI LLMìœ¼ë¡œ ì‹¤í–‰
    reflection_manager=reflection_manager,
    task_reflector=anthropic_task_reflector,  # â­ Anthropicìœ¼ë¡œ ì„±ì°°
)
```

### Self-Reflectionê³¼ì˜ ì½”ë“œ ë¹„êµ

**Self-Reflection ì½”ë“œ:** [self_reflection/main.py#L427-L440](../self_reflection/main.py#L427-L440)
```python
# Self-Reflection: ëª¨ë“  ì‘ì—…ì— ë™ì¼í•œ LLM ì‚¬ìš©
llm = ChatOpenAI(model=settings.openai_smart_model)

reflection_manager = ReflectionManager(file_path="tmp/self_reflection_db.json")

task_reflector = TaskReflector(
    llm=llm,  # â­ ë™ì¼í•œ LLM ì‚¬ìš©
    reflection_manager=reflection_manager
)

agent = ReflectiveAgent(
    llm=llm,  # â­ ì‹¤í–‰ë„ ê°™ì€ LLM
    reflection_manager=reflection_manager,
    task_reflector=task_reflector  # â­ ì„±ì°°ë„ ê°™ì€ LLM
)
```

**Cross-Reflection ì½”ë“œ:** [cross_reflection/main.py#L52-L86](main.py#L52-L86)
```python
# Cross-Reflection: ì‹¤í–‰ê³¼ ì„±ì°°ì— ë‹¤ë¥¸ LLM ì‚¬ìš©
openai_llm = ChatOpenAI(model=settings.openai_smart_model)
anthropic_llm = ChatAnthropic(model=settings.anthropic_smart_model)

reflection_manager = ReflectionManager(file_path="tmp/cross_reflection_db.json")

anthropic_task_reflector = TaskReflector(
    llm=anthropic_llm,  # â­ Anthropic LLM ì‚¬ìš©
    reflection_manager=reflection_manager
)

agent = ReflectiveAgent(
    llm=openai_llm,  # â­ OpenAI LLMìœ¼ë¡œ ì‹¤í–‰
    reflection_manager=reflection_manager,
    task_reflector=anthropic_task_reflector  # â­ Anthropic LLMìœ¼ë¡œ ì„±ì°°
)
```

**ì°¨ì´ì  ìš”ì•½:**
- `openai_llm`: íƒœìŠ¤í¬ ì‹¤í–‰ ì „ìš©
- `anthropic_llm`: ì„±ì°°(reflection) ì „ìš©
- ë™ì¼í•œ `ReflectiveAgent` í´ë˜ìŠ¤ ì‚¬ìš© (ì¸í”„ë¼ ì¬ì‚¬ìš©)
- ë‹¨ì§€ LLMë§Œ ë‹¤ë¥´ê²Œ ì„¤ì •

---

## êµ¬ì²´ì ì¸ ì˜ˆì‹œ: ì½”ë“œ ë¦¬ë·° ì—ì´ì „íŠ¸

### ì´ˆê¸° ì…ë ¥

**ì‚¬ìš©ì ì¿¼ë¦¬:**
```
"Python ì›¹ í¬ë¡¤ëŸ¬ êµ¬í˜„ ëª¨ë²” ì‚¬ë¡€ ì¡°ì‚¬"
```

**LLM ì„¤ì •:**
- ì‹¤í–‰ LLM: OpenAI GPT-4
- ì„±ì°° LLM: Anthropic Claude

---

## 1ë‹¨ê³„: ëª©í‘œ ì„¤ì • (Goal Setting)

**ì½”ë“œ ì°¸ì¡°:** [self_reflection/main.py#L298-L310](../self_reflection/main.py#L298-L310)

**ì‚¬ìš© LLM:** OpenAI GPT-4

ì´ ë‹¨ê³„ëŠ” Self-Reflectionê³¼ ë™ì¼í•˜ê²Œ OpenAI LLMì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### 1-1. ê³¼ê±° íšŒê³  ê²€ìƒ‰

```python
relevant_reflections = reflection_manager.get_relevant_reflections(query)
# ì˜ˆì‹œ: "Python í¬ë¡¤ëŸ¬" ê´€ë ¨ ê³¼ê±° ì„±ì°° 3ê°œ ê²€ìƒ‰
```

### 1-2. ê¸°ë³¸ ëª©í‘œ ìƒì„± (PassiveGoalCreator)

**ì…ë ¥:**
```
"Python ì›¹ í¬ë¡¤ëŸ¬ êµ¬í˜„ ëª¨ë²” ì‚¬ë¡€ ì¡°ì‚¬"
```

**ì¶œë ¥:**
```
"Pythonìœ¼ë¡œ ì›¹ í¬ë¡¤ëŸ¬ë¥¼ êµ¬í˜„í•  ë•Œì˜ ëª¨ë²” ì‚¬ë¡€, ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬,
ì—ëŸ¬ í•¸ë“¤ë§ ë°©ë²•, ì„±ëŠ¥ ìµœì í™” ê¸°ë²•ì„ ì¸í„°ë„·ì—ì„œ ì¡°ì‚¬í•˜ê³ 
ì‹¤ë¬´ ê°€ì´ë“œë¥¼ ì‘ì„±í•œë‹¤."
```

### 1-3. ëª©í‘œ ìµœì í™” (PromptOptimizer - SMART)

**ì¶œë ¥:**
```
Specific: requests, BeautifulSoup, Scrapyì™€ ê°™ì€ ì£¼ìš” í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜
          íŠ¹ì§•ê³¼ ì‚¬ìš©ë²•, robots.txt ì¤€ìˆ˜, ìš”ì²­ ì œí•œ(Rate limiting),
          ì—ëŸ¬ í•¸ë“¤ë§, ë°ì´í„° ì €ì¥ ë°©ì‹ì„ ì¡°ì‚¬í•œë‹¤.

Measurable: ìµœì†Œ 3ê°œì˜ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¹„êµí•˜ê³ , ê°ê°ì— ëŒ€í•´
            ì¥ë‹¨ì ê³¼ ì½”ë“œ ì˜ˆì œë¥¼ í¬í•¨í•œë‹¤.

Achievable: ê³µì‹ ë¬¸ì„œì™€ ê¸°ìˆ  ë¸”ë¡œê·¸ì—ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•œ ì •ë³´ë¡œ ì œí•œí•œë‹¤.

Relevant: ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤ìš©ì ì¸ ê¸°ë²•ì— ì´ˆì ì„ ë§ì¶˜ë‹¤.

Time-bound: 2024ë…„ ì´í›„ ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì‚¬í•œë‹¤.
```

### 1-4. ì‘ë‹µ í˜•ì‹ ìµœì í™” (ResponseOptimizer)

**ì¶œë ¥:**
```
### ì‘ë‹µ ì‚¬ì–‘
- í†¤: ê¸°ìˆ ì ì´ê³  ì‹¤ìš©ì ì¸ í†¤
- êµ¬ì¡°: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì†Œê°œ â†’ ëª¨ë²” ì‚¬ë¡€ â†’ ì½”ë“œ ì˜ˆì œ ìˆœì„œ
- ì´ˆì : ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ íŒ¨í„´

### AI ì—ì´ì „íŠ¸ ì§€ì¹¨
1. ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì„¤ì¹˜ ë°©ë²•, ì£¼ìš” ê¸°ëŠ¥, ì¥ë‹¨ì ì„ í¬í•¨í•  ê²ƒ
2. ì½”ë“œ ì˜ˆì œëŠ” ì£¼ì„ê³¼ í•¨ê»˜ ì œê³µí•˜ê³  ì—ëŸ¬ ì²˜ë¦¬ë¥¼ í¬í•¨í•  ê²ƒ
3. robots.txt ì¤€ìˆ˜ì™€ ìœ¤ë¦¬ì  í¬ë¡¤ë§ ê°•ì¡°
4. ì„±ëŠ¥ ìµœì í™” ê¸°ë²•(ë™ì‹œì„±, ìºì‹± ë“±) í¬í•¨
```

---

## 2ë‹¨ê³„: ëª©í‘œ ë¶„í•´ (Decompose Query)

**ì½”ë“œ ì°¸ì¡°:** [self_reflection/main.py#L142-L165](../self_reflection/main.py#L142-L165)

**ì‚¬ìš© LLM:** OpenAI GPT-4

### QueryDecomposer ì‹¤í–‰

**ì…ë ¥:** optimized_goal
**ì¶œë ¥:** 3~5ê°œì˜ íƒœìŠ¤í¬

```python
DecomposedTasks(
    values=[
        """
        íƒœìŠ¤í¬ 1: requests, BeautifulSoup, Scrapy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ íŠ¹ì§•,
        ì„¤ì¹˜ ë°©ë²•, ì£¼ìš” ê¸°ëŠ¥ì„ ì¡°ì‚¬í•˜ê³ , ê°ê°ì˜ ì¥ë‹¨ì ì„ ë¹„êµí•˜ì—¬
        ì–´ë–¤ ìƒí™©ì— ì í•©í•œì§€ ë¶„ì„í•œë‹¤.
        """,

        """
        íƒœìŠ¤í¬ 2: ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™(robots.txt í™•ì¸,
        User-Agent ì„¤ì •, ìš”ì²­ ì œí•œ ë“±)ê³¼ ë²•ì  ê³ ë ¤ì‚¬í•­ì„ ì¡°ì‚¬í•˜ê³ ,
        ì‹¤ì œ êµ¬í˜„ ë°©ë²•ì„ ì˜ˆì œ ì½”ë“œì™€ í•¨ê»˜ ì •ë¦¬í•œë‹¤.
        """,

        """
        íƒœìŠ¤í¬ 3: ì›¹ í¬ë¡¤ëŸ¬ì˜ ì—ëŸ¬ í•¸ë“¤ë§ íŒ¨í„´(íƒ€ì„ì•„ì›ƒ, ì—°ê²° ì‹¤íŒ¨,
        HTTP ì˜¤ë¥˜ ì½”ë“œ ì²˜ë¦¬)ê³¼ ì¬ì‹œë„ ë¡œì§ êµ¬í˜„ ë°©ë²•ì„ ì¡°ì‚¬í•˜ê³ 
        ì‹¤ë¬´ì—ì„œ ì‚¬ìš©ë˜ëŠ” ëª¨ë²” ì‚¬ë¡€ë¥¼ ìˆ˜ì§‘í•œë‹¤.
        """,

        """
        íƒœìŠ¤í¬ 4: ì›¹ í¬ë¡¤ëŸ¬ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•(ë¹„ë™ê¸° ì²˜ë¦¬, ë™ì‹œì„± ì œì–´,
        ìºì‹±, í”„ë¡ì‹œ ì‚¬ìš©)ì„ ì¡°ì‚¬í•˜ê³ , Pythonì˜ asyncio, aiohttpë¥¼
        í™œìš©í•œ êµ¬í˜„ ì˜ˆì œë¥¼ ì°¾ì•„ ì •ë¦¬í•œë‹¤.
        """
    ]
)
```

---

## 3ë‹¨ê³„: íƒœìŠ¤í¬ ì‹¤í–‰ ë° ì„±ì°° (Execute & Reflect)

ì´ ë‹¨ê³„ê°€ **Cross-Reflectionì˜ í•µì‹¬**ì…ë‹ˆë‹¤.

### 3-1. íƒœìŠ¤í¬ ì‹¤í–‰ (OpenAI)

**ì½”ë“œ ì°¸ì¡°:** [self_reflection/main.py#L168-L202](../self_reflection/main.py#L168-L202)

**ì‚¬ìš© LLM:** â­ **OpenAI GPT-4**

```python
class TaskExecutor:
    def __init__(self, llm: ChatOpenAI, ...):  # OpenAI LLM
        self.llm = llm
        ...

    def run(self, task: str) -> str:
        agent = create_react_agent(self.llm, self.tools)  # OpenAI ì—ì´ì „íŠ¸
        result = agent.invoke({...})
        return result
```

### ğŸ”„ ì²« ë²ˆì§¸ ë°˜ë³µ (Task 1/4)

#### ì‹¤í–‰ ë‹¨ê³„ (OpenAI)

**ì…ë ¥:**
```
"requests, BeautifulSoup, Scrapy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ íŠ¹ì§•, ì„¤ì¹˜ ë°©ë²•,
ì£¼ìš” ê¸°ëŠ¥ì„ ì¡°ì‚¬í•˜ê³ ..."
```

**OpenAI ReAct ì—ì´ì „íŠ¸ ë™ì‘:**
```
[OpenAI Thought]
ì›¹ í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ë¹„êµ ì¡°ì‚¬í•´ì•¼ í•¨

[OpenAI Action]
tavily_search("Python web scraping libraries comparison requests beautifulsoup scrapy")

[OpenAI Observation]
ê²€ìƒ‰ ê²°ê³¼:
1. requests: HTTP ìš”ì²­ ë¼ì´ë¸ŒëŸ¬ë¦¬
2. BeautifulSoup: HTML íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬
3. Scrapy: ì „ë¬¸ í¬ë¡¤ë§ í”„ë ˆì„ì›Œí¬

[OpenAI Thought]
ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë‹ˆ ì •ë¦¬í•˜ì

[OpenAI Final Answer]
```

**ì‹¤í–‰ ê²°ê³¼:**
```markdown
# Python ì›¹ í¬ë¡¤ë§ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¹„êµ

## 1. requests
### íŠ¹ì§•
requestsëŠ” Pythonì—ì„œ HTTP ìš”ì²­ì„ ë³´ë‚´ê¸° ìœ„í•œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

### ì„¤ì¹˜
```bash
pip install requests
```

### ì£¼ìš” ê¸°ëŠ¥
- HTTP GET/POST ìš”ì²­
- ì„¸ì…˜ ê´€ë¦¬
- í—¤ë” ì„¤ì •
- ì¿ í‚¤ ì²˜ë¦¬

### ì¥ì 
- ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ API
- ê´‘ë²”ìœ„í•œ ë¬¸ì„œí™”
- ì•ˆì •ì ì´ê³  ì„±ìˆ™í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

### ë‹¨ì 
- HTML íŒŒì‹± ê¸°ëŠ¥ ì—†ìŒ (BeautifulSoupê³¼ í•¨ê»˜ ì‚¬ìš© í•„ìš”)
- ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì› ì•ˆ í•¨

### ì í•©í•œ ê²½ìš°
- ê°„ë‹¨í•œ HTTP ìš”ì²­
- RESTful API í˜¸ì¶œ
- ì‘ì€ ê·œëª¨ì˜ í¬ë¡¤ë§

### ì½”ë“œ ì˜ˆì œ
```python
import requests

response = requests.get('https://example.com')
print(response.status_code)
print(response.text)
```

## 2. BeautifulSoup
### íŠ¹ì§•
HTMLê³¼ XMLì„ íŒŒì‹±í•˜ê³  ê²€ìƒ‰í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

### ì„¤ì¹˜
```bash
pip install beautifulsoup4
pip install lxml  # íŒŒì„œ
```

### ì£¼ìš” ê¸°ëŠ¥
- HTML/XML íŒŒì‹±
- CSS ì„ íƒì ì§€ì›
- íƒœê·¸ ê²€ìƒ‰ ë° íƒìƒ‰
- ë°ì´í„° ì¶”ì¶œ

### ì¥ì 
- ì§ê´€ì ì¸ API
- ê°•ë ¥í•œ íŒŒì‹± ëŠ¥ë ¥
- requestsì™€ ì™„ë²½í•œ ì¡°í•©

### ë‹¨ì 
- HTTP ìš”ì²­ ê¸°ëŠ¥ ì—†ìŒ (requestsì™€ í•¨ê»˜ ì‚¬ìš©)
- ëŒ€ê·œëª¨ í¬ë¡¤ë§ì—ëŠ” ëŠë¦¼

### ì í•©í•œ ê²½ìš°
- HTML ë°ì´í„° ì¶”ì¶œ
- ì •ì  ì›¹í˜ì´ì§€ íŒŒì‹±
- ì¤‘ì†Œ ê·œëª¨ í¬ë¡¤ë§

### ì½”ë“œ ì˜ˆì œ
```python
import requests
from bs4 import BeautifulSoup

response = requests.get('https://example.com')
soup = BeautifulSoup(response.text, 'lxml')

title = soup.find('h1').text
links = soup.find_all('a')
```

## 3. Scrapy
### íŠ¹ì§•
ëŒ€ê·œëª¨ ì›¹ í¬ë¡¤ë§ì„ ìœ„í•œ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

### ì„¤ì¹˜
```bash
pip install scrapy
```

### ì£¼ìš” ê¸°ëŠ¥
- ë¹„ë™ê¸° ì²˜ë¦¬
- ìë™ ì¬ì‹œë„
- íŒŒì´í”„ë¼ì¸ (ë°ì´í„° ì €ì¥)
- ë¯¸ë“¤ì›¨ì–´ (ì»¤ìŠ¤í„°ë§ˆì´ì§•)
- robots.txt ìë™ ì¤€ìˆ˜

### ì¥ì 
- ë§¤ìš° ë¹ ë¦„ (ë¹„ë™ê¸° ì²˜ë¦¬)
- ëŒ€ê·œëª¨ í¬ë¡¤ë§ì— ìµœì í™”
- í’ë¶€í•œ ê¸°ëŠ¥ ì œê³µ
- í™•ì¥ì„± ë›°ì–´ë‚¨

### ë‹¨ì 
- í•™ìŠµ ê³¡ì„ ì´ ë†’ìŒ
- ê°„ë‹¨í•œ ì‘ì—…ì—ëŠ” ê³¼í•¨
- í”„ë¡œì íŠ¸ êµ¬ì¡°ê°€ ë³µì¡

### ì í•©í•œ ê²½ìš°
- ëŒ€ê·œëª¨ í¬ë¡¤ë§
- ë³µì¡í•œ í¬ë¡¤ë§ ë¡œì§
- í”„ë¡œë•ì…˜ í™˜ê²½

### ì½”ë“œ ì˜ˆì œ
```python
import scrapy

class ExampleSpider(scrapy.Spider):
    name = 'example'
    start_urls = ['https://example.com']

    def parse(self, response):
        for title in response.css('h1::text'):
            yield {'title': title.get()}
```

## ë¹„êµí‘œ

| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ë‚œì´ë„ | ì†ë„ | ê·œëª¨ | ë¹„ë™ê¸° |
|----------|-------|------|------|--------|
| requests | ì‰¬ì›€ | ëŠë¦¼ | ì†Œê·œëª¨ | X |
| BeautifulSoup | ì‰¬ì›€ | ë³´í†µ | ì¤‘ê·œëª¨ | X |
| Scrapy | ì–´ë ¤ì›€ | ë¹ ë¦„ | ëŒ€ê·œëª¨ | O |

## ì„ íƒ ê°€ì´ë“œ
- **ê°„ë‹¨í•œ í¬ë¡¤ë§**: requests + BeautifulSoup
- **ì¤‘ê·œëª¨ í”„ë¡œì íŠ¸**: BeautifulSoup
- **ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜**: Scrapy

ì¶œì²˜:
- https://requests.readthedocs.io/
- https://www.crummy.com/software/BeautifulSoup/
- https://docs.scrapy.org/
```

#### ì„±ì°° ë‹¨ê³„ (Anthropic)

**ì½”ë“œ ì°¸ì¡°:** [self_reflection/main.py#L331-L349](../self_reflection/main.py#L331-L349)

**ì‚¬ìš© LLM:** â­ **Anthropic Claude**

```python
def _reflect_on_task(self, state: ReflectiveAgentState) -> dict[str, Any]:
    current_task = state.tasks[state.current_task_index]
    current_result = state.results[-1]

    # TaskReflectorëŠ” Anthropic LLMì„ ì‚¬ìš©
    reflection = self.task_reflector.run(
        task=current_task,
        result=current_result
    )
    ...
```

**Anthropicì˜ ì„±ì°° í”„ë¡¬í”„íŠ¸:** [common/reflection_manager.py#L118-L132](../common/reflection_manager.py#L118-L132)
```
ì£¼ì–´ì§„ íƒœìŠ¤í¬ ë‚´ìš©:
requests, BeautifulSoup, Scrapy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ íŠ¹ì§•...

íƒœìŠ¤í¬ ì‹¤í–‰ ê²°ê³¼:
# Python ì›¹ í¬ë¡¤ë§ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¹„êµ...

ë‹¹ì‹ ì€ ê³ ë„ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ê°€ì§„ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ìœ„ íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³ , ì´ íƒœìŠ¤í¬ì— ëŒ€í•œ ì ‘ê·¼ì´ ì ì ˆí–ˆëŠ”ì§€ ë°˜ì„±í•˜ì„¸ìš”.

ë¦¬í”Œë ‰ì…˜:
ì´ íƒœìŠ¤í¬ì— ëŒ€í•œ ì ‘ê·¼ ì‹œ ë‹¹ì‹ ì˜ ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ë‚˜ ë°©ë²•ì„ ë˜ëŒì•„ë³´ì„¸ìš”.
ê°œì„ í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì´ ìˆì—ˆìŠµë‹ˆê¹Œ?

íŒì •:
- ê²°ê³¼ì˜ ì ì ˆì„±: íƒœìŠ¤í¬ ì‹¤í–‰ ê²°ê³¼ê°€ ì ì ˆí–ˆë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?
- íŒì •ì˜ ìì‹ ê°: ìœ„ íŒë‹¨ì— ëŒ€í•œ ìì‹ ê° ì •ë„ (0~1)
- íŒì •ì˜ ì´ìœ : íŒë‹¨ì— ì´ë¥¸ ì´ìœ ë¥¼ ê°„ê²°í•˜ê²Œ ë‚˜ì—´í•˜ì„¸ìš”.
```

**Anthropic Claudeì˜ ì„±ì°° ê²°ê³¼:**

```python
Reflection(
    id="abc123",
    task="requests, BeautifulSoup, Scrapy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ íŠ¹ì§•...",
    reflection="""
    ì„¸ ê°€ì§€ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ë¹„êµê°€ ì²´ê³„ì ì´ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
    ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì„¤ì¹˜ ë°©ë²•, ì¥ë‹¨ì , ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€ê°€ ì˜ ì œì‹œë˜ì—ˆê³ ,
    ì‹¤ì œ ì½”ë“œ ì˜ˆì œë¥¼ í†µí•´ ì‹¤ìš©ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤. ë¹„êµí‘œë¥¼ í†µí•œ ì‹œê°í™”ë„ íš¨ê³¼ì ì…ë‹ˆë‹¤.

    ë‹¤ë§Œ, ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë‚˜ ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œì˜
    ì‚¬ìš© í†µê³„ê°€ í¬í•¨ë˜ì—ˆë‹¤ë©´ ë” ì„¤ë“ë ¥ ìˆì—ˆì„ ê²ƒì…ë‹ˆë‹¤.
    ë‹¤ìŒë²ˆì—ëŠ” ì •ëŸ‰ì  ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ë¹„êµì˜ ê¹Šì´ë¥¼ ë”í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    """,
    judgment=ReflectionJudgment(
        needs_retry=False,  # â­ í†µê³¼
        confidence=0.9,
        reasons=[
            "ì„¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•µì‹¬ íŠ¹ì§•ì´ ëª…í™•í•˜ê²Œ ì„¤ëª…ë¨",
            "ì½”ë“œ ì˜ˆì œê°€ ì‹¤ìš©ì ì´ê³  ì£¼ì„ì´ ì˜ ë‹¬ë ¤ ìˆìŒ",
            "ë¹„êµí‘œë¥¼ í†µí•´ ì„ íƒ ê¸°ì¤€ì´ ëª…í™•í•¨",
            "ë‹¤ë§Œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ê°€ ë¶€ì¡±í•¨"
        ]
    )
)
```

**ì¡°ê±´ íŒë‹¨:** [self_reflection/main.py#L351-L366](../self_reflection/main.py#L351-L366)
```python
def _should_retry_or_continue(self, state: ReflectiveAgentState) -> str:
    latest_reflection = self.reflection_manager.get_reflection(
        state.reflection_ids[-1]
    )

    if latest_reflection.judgment.needs_retry and state.retry_count < self.max_retries:
        return "retry"  # ì¬ì‹œë„
    elif state.current_task_index < len(state.tasks) - 1:
        return "continue"  # ë‹¤ìŒ íƒœìŠ¤í¬
    else:
        return "finish"  # ì™„ë£Œ
```

**ê²°ê³¼:** `needs_retry=False` â†’ ë‹¤ìŒ íƒœìŠ¤í¬ë¡œ ì§„í–‰

---

### ğŸ”„ ë‘ ë²ˆì§¸ ë°˜ë³µ (Task 2/4) - ì¬ì‹œë„ ë°œìƒ ì˜ˆì‹œ

#### ì‹¤í–‰ ë‹¨ê³„ (OpenAI)

**ì…ë ¥:**
```
"ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™(robots.txt í™•ì¸,
User-Agent ì„¤ì •, ìš”ì²­ ì œí•œ ë“±)ê³¼ ë²•ì  ê³ ë ¤ì‚¬í•­ì„ ì¡°ì‚¬..."
```

**OpenAI ì‹¤í–‰ ê²°ê³¼ (ì´ˆì•ˆ):**
```markdown
# ì›¹ í¬ë¡¤ë§ ìœ¤ë¦¬ì  ê·œì¹™

## robots.txt
robots.txt íŒŒì¼ì„ í™•ì¸í•˜ì—¬ í¬ë¡¤ë§ í—ˆìš© ë²”ìœ„ë¥¼ íŒŒì•…í•´ì•¼ í•©ë‹ˆë‹¤.

## User-Agent ì„¤ì •
í¬ë¡¤ëŸ¬ ì‹ë³„ì„ ìœ„í•´ User-Agentë¥¼ ì„¤ì •í•˜ì„¸ìš”.

```python
headers = {
    'User-Agent': 'MyBot/1.0'
}
```

## ìš”ì²­ ì œí•œ
ì„œë²„ì— ê³¼ë¶€í•˜ë¥¼ ì£¼ì§€ ì•Šë„ë¡ ìš”ì²­ ê°„ê²©ì„ ë‘ì„¸ìš”.

```python
import time
time.sleep(1)
```

## ë²•ì  ê³ ë ¤ì‚¬í•­
ì €ì‘ê¶Œê³¼ ê°œì¸ì •ë³´ ë³´í˜¸ë²•ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.
```

#### ì„±ì°° ë‹¨ê³„ (Anthropic) - ì¬ì‹œë„ ìš”ì²­

**Anthropic Claudeì˜ ì„±ì°°:**

```python
Reflection(
    id="def456",
    task="ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...",
    reflection="""
    ìœ¤ë¦¬ì  ê·œì¹™ì˜ ì£¼ìš” í•­ëª©ë“¤ì€ ì–¸ê¸‰ë˜ì—ˆìœ¼ë‚˜, ê° í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ì´
    ë„ˆë¬´ í”¼ìƒì ì´ê³  ì‹¤ë¬´ì  êµ¬í˜„ ë°©ë²•ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.

    íŠ¹íˆ ë‹¤ìŒ ë¶€ë¶„ë“¤ì´ ê°œì„  í•„ìš”:
    1. robots.txtë¥¼ ì‹¤ì œë¡œ íŒŒì‹±í•˜ê³  ì¤€ìˆ˜í•˜ëŠ” ì½”ë“œ ì˜ˆì œ ì—†ìŒ
    2. ìš”ì²­ ì œí•œì˜ ì ì ˆí•œ ê°„ê²©(ì˜ˆ: 1ì´ˆ)ì— ëŒ€í•œ ê·¼ê±° ë¶€ì¡±
    3. ë²•ì  ê³ ë ¤ì‚¬í•­ì´ ì¶”ìƒì ì´ë©° êµ¬ì²´ì ì¸ ê°€ì´ë“œë¼ì¸ ì—†ìŒ
    4. User-Agent ì‹ë³„ì í¬ë§·ì˜ ëª¨ë²” ì‚¬ë¡€ ëˆ„ë½

    íƒœìŠ¤í¬ê°€ "ì‹¤ì œ êµ¬í˜„ ë°©ë²•ì„ ì˜ˆì œ ì½”ë“œì™€ í•¨ê»˜"ë¥¼ ìš”êµ¬í–ˆìœ¼ë‚˜,
    ì½”ë“œê°€ ë„ˆë¬´ ê°„ëµí•˜ê³  ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•˜ê¸° ì–´ë ¤ì›€.

    ë‹¤ìŒë²ˆì—ëŠ” ê° ê·œì¹™ì— ëŒ€í•´ ì‹¤ì œ ë™ì‘í•˜ëŠ” ì™„ì „í•œ ì½”ë“œ ì˜ˆì œë¥¼ ì œê³µí•˜ê³ ,
    ì™œ ê·¸ëŸ° ë°©ì‹ì´ ê¶Œì¥ë˜ëŠ”ì§€ ì´ìœ ë¥¼ í•¨ê»˜ ì„¤ëª…í•  ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    """,
    judgment=ReflectionJudgment(
        needs_retry=True,  # â­ ì¬ì‹œë„ í•„ìš”!
        confidence=0.85,
        reasons=[
            "ì£¼ìš” í•­ëª©ì€ ë‹¤ë¤˜ìœ¼ë‚˜ ê¹Šì´ê°€ ë¶€ì¡±í•¨",
            "ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì œê°€ ë¯¸í¡í•¨",
            "ë²•ì  ê³ ë ¤ì‚¬í•­ì´ ë„ˆë¬´ ì¶”ìƒì ì„",
            "robots.txt íŒŒì‹± ë°©ë²•ì´ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œë˜ì§€ ì•ŠìŒ"
        ]
    )
)
```

**ì¡°ê±´ íŒë‹¨:**
```python
# needs_retry=Trueì´ê³  retry_count(0) < max_retries(2)
â†’ "retry" ë°˜í™˜ â†’ execute_taskë¡œ ì¬ì´ë™
```

#### ì¬ì‹¤í–‰ ë‹¨ê³„ (OpenAI) - ê°œì„ ëœ ë²„ì „

**OpenAIê°€ Anthropicì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì¬ì‹¤í–‰:**

**ì¬ì‹¤í–‰ ê²°ê³¼:**
```markdown
# ì›¹ í¬ë¡¤ë§ ìœ¤ë¦¬ì  ê·œì¹™ ë° ë²•ì  ê³ ë ¤ì‚¬í•­

## 1. robots.txt í™•ì¸ ë° ì¤€ìˆ˜

### robots.txtë€?
ì›¹ì‚¬ì´íŠ¸ ë£¨íŠ¸ì— ìœ„ì¹˜í•œ íŒŒì¼ë¡œ, í¬ë¡¤ëŸ¬ì—ê²Œ ì ‘ê·¼ í—ˆìš©/ì œí•œ ë²”ìœ„ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.

### ì˜¬ë°”ë¥¸ í™•ì¸ ë°©ë²•
```python
import requests
from urllib.robotparser import RobotFileParser

def can_fetch(url):
    """
    robots.txtë¥¼ í™•ì¸í•˜ì—¬ í¬ë¡¤ë§ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ë°˜í™˜
    """
    # robots.txt URL ìƒì„±
    from urllib.parse import urlparse
    parsed = urlparse(url)
    robots_url = f"{parsed.scheme}://{parsed.netloc}/robots.txt"

    # RobotFileParserë¡œ íŒŒì‹±
    rp = RobotFileParser()
    rp.set_url(robots_url)
    rp.read()

    # User-Agent 'MyBot'ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸
    return rp.can_fetch("MyBot", url)

# ì‚¬ìš© ì˜ˆì‹œ
url = "https://example.com/page"
if can_fetch(url):
    response = requests.get(url)
else:
    print("robots.txtì—ì„œ í¬ë¡¤ë§ì„ ì œí•œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
```

**ì¤‘ìš”:** robots.txt íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ëª¨ë“  ì ‘ê·¼ì´ í—ˆìš©ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼í•˜ì§€ë§Œ,
ìœ¤ë¦¬ì ìœ¼ë¡œëŠ” ì›¹ë§ˆìŠ¤í„°ì—ê²Œ ë¬¸ì˜í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.

## 2. User-Agent ì„¤ì •

### ì™œ í•„ìš”í•œê°€?
- ì„œë²„ ê´€ë¦¬ìê°€ í¬ë¡¤ëŸ¬ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆìŒ
- ë¬¸ì œ ë°œìƒ ì‹œ ì—°ë½ ê°€ëŠ¥
- ì°¨ë‹¨ ìœ„í—˜ ê°ì†Œ

### ëª¨ë²” ì‚¬ë¡€ í¬ë§·
```
BotName/Version (+URL; contact@email.com)
```

### êµ¬í˜„ ì˜ˆì‹œ
```python
import requests

# ì˜¬ë°”ë¥¸ User-Agent ì„¤ì •
headers = {
    'User-Agent': 'MyResearchBot/1.0 (+https://myproject.com/bot; contact@myproject.com)'
}

response = requests.get('https://example.com', headers=headers)
```

**ê¶Œì¥ ì‚¬í•­:**
- ë´‡ ì´ë¦„ê³¼ ë²„ì „ ëª…ì‹œ
- í”„ë¡œì íŠ¸ URL ì œê³µ
- ì—°ë½ì²˜ ì´ë©”ì¼ í¬í•¨

### Scrapyì—ì„œì˜ ì„¤ì •
```python
# settings.py
USER_AGENT = 'MyResearchBot/1.0 (+https://myproject.com/bot; contact@myproject.com)'
```

## 3. ìš”ì²­ ì œí•œ (Rate Limiting)

### ì™œ í•„ìš”í•œê°€?
- ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
- IP ì°¨ë‹¨ ìœ„í—˜ ê°ì†Œ
- ìœ¤ë¦¬ì  í¬ë¡¤ë§

### ì ì ˆí•œ ê°„ê²© ê¸°ì¤€
- **ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸**: 1~3ì´ˆ
- **ëŒ€í˜• ì‚¬ì´íŠ¸**: 0.5~1ì´ˆ
- **ì†Œí˜• ì‚¬ì´íŠ¸**: 3~5ì´ˆ

**ì¶œì²˜:** Scrapy ê³µì‹ ë¬¸ì„œ ê¶Œì¥ì‚¬í•­

### requests êµ¬í˜„
```python
import requests
import time

urls = ['url1', 'url2', 'url3']

for url in urls:
    response = requests.get(url)
    # ê° ìš”ì²­ í›„ 2ì´ˆ ëŒ€ê¸°
    time.sleep(2)
```

### Scrapy êµ¬í˜„ (ê¶Œì¥)
```python
# settings.py

# ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ
CONCURRENT_REQUESTS = 16

# ë„ë©”ì¸ë³„ ë™ì‹œ ìš”ì²­ ìˆ˜
CONCURRENT_REQUESTS_PER_DOMAIN = 8

# ë‹¤ìš´ë¡œë“œ ì§€ì—° (ì´ˆ)
DOWNLOAD_DELAY = 2

# AutoThrottle í™œì„±í™” (ìë™ ì†ë„ ì¡°ì ˆ)
AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 1
AUTOTHROTTLE_MAX_DELAY = 10
AUTOTHROTTLE_TARGET_CONCURRENCY = 2.0
```

**AutoThrottleì˜ ì¥ì :**
- ì„œë²„ ì‘ë‹µ ì‹œê°„ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì†ë„ ì¡°ì ˆ
- ì„œë²„ ë¶€í•˜ê°€ ë†’ìœ¼ë©´ ëŠë ¤ì§€ê³ , ë‚®ìœ¼ë©´ ë¹¨ë¼ì§

## 4. ë²•ì  ê³ ë ¤ì‚¬í•­

### ì €ì‘ê¶Œë²•
**ë¬¸ì œ:** í¬ë¡¤ë§í•œ ì½˜í…ì¸ ì˜ ì €ì‘ê¶Œì€ ì› ì €ì‘ìì—ê²Œ ìˆìŒ

**í•´ê²°ì±…:**
- ê³µê°œ API ì‚¬ìš© ìš°ì„  ê²€í† 
- ì €ì‘ê¶Œ í‘œê¸° ìœ ì§€
- ìƒì—…ì  ì‚¬ìš© ì‹œ í—ˆê°€ í•„ìš”
- Fair Use ì›ì¹™ ì¤€ìˆ˜ (ì—°êµ¬, êµìœ¡ ëª©ì )

### ê°œì¸ì •ë³´ ë³´í˜¸ë²• (GDPR, ê°œì¸ì •ë³´ë³´í˜¸ë²•)
**ìœ„ë°˜ ì‚¬ë¡€:**
- ì´ë©”ì¼ ì£¼ì†Œ, ì „í™”ë²ˆí˜¸ ë¬´ë‹¨ ìˆ˜ì§‘
- ê°œì¸ ì‹ë³„ ê°€ëŠ¥í•œ ì •ë³´ ì €ì¥

**ì¤€ìˆ˜ ë°©ë²•:**
```python
import re

def anonymize_email(text):
    """ì´ë©”ì¼ ì£¼ì†Œë¥¼ ìµëª…í™”"""
    return re.sub(
        r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
        '[ì´ë©”ì¼ ì œê±°ë¨]',
        text
    )

# ì‚¬ìš© ì˜ˆì‹œ
content = "ì—°ë½ì²˜: contact@example.com"
safe_content = anonymize_email(content)
```

### ì„œë¹„ìŠ¤ ì´ìš©ì•½ê´€ (Terms of Service)
**í™•ì¸ ì‚¬í•­:**
- í¬ë¡¤ë§ ëª…ì‹œì  ê¸ˆì§€ ì—¬ë¶€
- API ì œê³µ ì—¬ë¶€ í™•ì¸
- ë°ì´í„° ì‚¬ìš© ì œí•œ ë²”ìœ„

**ì˜ˆì‹œ:** LinkedIn, Facebook ë“±ì€ ì´ìš©ì•½ê´€ì—ì„œ í¬ë¡¤ë§ì„ ëª…ì‹œì ìœ¼ë¡œ ê¸ˆì§€

### ë²•ì  ì•ˆì „ì¥ì¹˜
```python
# í”„ë¡œì íŠ¸ì— LICENSE íŒŒì¼ ì¶”ê°€
# README.mdì— ë©´ì±… ì¡°í•­ ëª…ì‹œ

"""
ì´ í¬ë¡¤ëŸ¬ëŠ” êµìœ¡ ë° ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
ì‚¬ìš©ìëŠ” ëŒ€ìƒ ì›¹ì‚¬ì´íŠ¸ì˜ robots.txt, ì´ìš©ì•½ê´€,
ê´€ë ¨ ë²•ë¥ ì„ ì¤€ìˆ˜í•  ì±…ì„ì´ ìˆìŠµë‹ˆë‹¤.
"""
```

## 5. ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸

í¬ë¡¤ë§ ì‹œì‘ ì „ í™•ì¸ì‚¬í•­:

- [ ] robots.txt í™•ì¸ ë° ì¤€ìˆ˜ ì½”ë“œ êµ¬í˜„
- [ ] ëª…í™•í•œ User-Agent ì„¤ì • (ì—°ë½ì²˜ í¬í•¨)
- [ ] ìš”ì²­ ê°„ê²© ì„¤ì • (ìµœì†Œ 1ì´ˆ)
- [ ] ëŒ€ìƒ ì‚¬ì´íŠ¸ ì´ìš©ì•½ê´€ ê²€í† 
- [ ] ê°œì¸ì •ë³´ ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸
- [ ] ë°ì´í„° ì €ì¥ ì‹œ ì €ì‘ê¶Œ í‘œê¸°
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ í¬ë¡¤ë§ ì¤‘ë‹¨ ë¡œì§ êµ¬í˜„
- [ ] ë¡œê·¸ ê¸°ë¡ìœ¼ë¡œ í¬ë¡¤ë§ ë‚´ì—­ ì¶”ì 

## ì°¸ê³  ìë£Œ
- Scrapy ê³µì‹ ë¬¸ì„œ: https://docs.scrapy.org/en/latest/topics/practices.html
- robots.txt ëª…ì„¸: https://www.robotstxt.org/
- GDPR ê°€ì´ë“œ: https://gdpr.eu/
- ê°œì¸ì •ë³´ë³´í˜¸ë²•: https://www.pipc.go.kr/
```

#### ì¬ì„±ì°° (Anthropic) - í†µê³¼

**Anthropic Claudeì˜ ì¬í‰ê°€:**

```python
Reflection(
    id="ghi789",
    task="ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...",
    reflection="""
    ì´ì „ í”¼ë“œë°±ì´ ì¶©ì‹¤íˆ ë°˜ì˜ë˜ì–´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.

    ê°œì„ ëœ ì :
    1. robots.txt íŒŒì‹±ì„ ìœ„í•œ ì™„ì „í•œ í•¨ìˆ˜ êµ¬í˜„ (RobotFileParser í™œìš©)
    2. User-Agent í¬ë§·ì˜ ëª¨ë²” ì‚¬ë¡€ì™€ êµ¬ì²´ì ì¸ ì´ìœ  ì œì‹œ
    3. ìš”ì²­ ì œí•œì— ëŒ€í•œ ì •ëŸ‰ì  ê¸°ì¤€ê³¼ ì¶œì²˜ ëª…ì‹œ
    4. ë²•ì  ê³ ë ¤ì‚¬í•­ì´ ì €ì‘ê¶Œë²•, ê°œì¸ì •ë³´ë³´í˜¸ë²•, ì´ìš©ì•½ê´€ìœ¼ë¡œ êµ¬ì¡°í™”ë¨
    5. ì‹¤ë¬´ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¡œ ì‹¤ìš©ì„± ê·¹ëŒ€í™”

    ëª¨ë“  ì½”ë“œ ì˜ˆì œê°€ ì‹¤ì œë¡œ ë™ì‘ ê°€ëŠ¥í•˜ë©°, ê° ê·œì¹™ì˜ í•„ìš”ì„±ê³¼
    êµ¬í˜„ ë°©ë²•ì´ ëª…í™•í•˜ê²Œ ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. íƒœìŠ¤í¬ ìš”êµ¬ì‚¬í•­ì„
    ì¶©ë¶„íˆ ë§Œì¡±í•˜ëŠ” ê³ í’ˆì§ˆ ê²°ê³¼ì…ë‹ˆë‹¤.
    """,
    judgment=ReflectionJudgment(
        needs_retry=False,  # â­ í†µê³¼!
        confidence=0.95,
        reasons=[
            "ëª¨ë“  ìœ¤ë¦¬ì  ê·œì¹™ì´ ì‹¤ë¬´ ìˆ˜ì¤€ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ë‹¤ë¤„ì§",
            "ì™„ì „íˆ ë™ì‘í•˜ëŠ” ì½”ë“œ ì˜ˆì œ ì œê³µ",
            "ë²•ì  ê³ ë ¤ì‚¬í•­ì´ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì„",
            "ì²´í¬ë¦¬ìŠ¤íŠ¸ë¡œ ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„± ë†’ì„"
        ]
    )
)
```

**ê²°ê³¼:** ë‹¤ìŒ íƒœìŠ¤í¬ë¡œ ì§„í–‰

---

### ğŸ”„ ì„¸ ë²ˆì§¸ & ë„¤ ë²ˆì§¸ ë°˜ë³µ (Task 3/4, 4/4)

ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ:
1. **OpenAI**ê°€ íƒœìŠ¤í¬ ì‹¤í–‰
2. **Anthropic**ì´ ê²°ê³¼ í‰ê°€
3. í•„ìš”ì‹œ ì¬ì‹œë„, í†µê³¼ ì‹œ ë‹¤ìŒ íƒœìŠ¤í¬

ìµœì¢…ì ìœ¼ë¡œ 4ê°œì˜ íƒœìŠ¤í¬ê°€ ëª¨ë‘ ì™„ë£Œë˜ê³ , ê°ê°ì˜ ì„±ì°° ê²°ê³¼ê°€ ì €ì¥ë©ë‹ˆë‹¤.

---

## 4ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„ (Aggregate Results)

**ì½”ë“œ ì°¸ì¡°:** [self_reflection/main.py#L372-L383](../self_reflection/main.py#L372-L383)

**ì‚¬ìš© LLM:** OpenAI GPT-4

### ì…ë ¥

```python
query = "Specific: requests, BeautifulSoup, Scrapyì™€ ê°™ì€ ì£¼ìš” í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬..."
results = [
    "# Python ì›¹ í¬ë¡¤ë§ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¹„êµ...",
    "# ì›¹ í¬ë¡¤ë§ ìœ¤ë¦¬ì  ê·œì¹™ ë° ë²•ì  ê³ ë ¤ì‚¬í•­...",
    "# ì›¹ í¬ë¡¤ëŸ¬ ì—ëŸ¬ í•¸ë“¤ë§ ëª¨ë²” ì‚¬ë¡€...",
    "# ì›¹ í¬ë¡¤ëŸ¬ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•..."
]
reflection_ids = ["abc123", "ghi789", "jkl012", "mno345"]
response_definition = "### ì‘ë‹µ ì‚¬ì–‘..."
```

### ì²˜ë¦¬

**Anthropicì˜ ì„±ì°°ì„ ì°¸ê³ í•˜ì—¬ ìµœì¢… ê²°ê³¼ ìƒì„±:**

```python
# ê° reflection_idë¡œ ì„±ì°° ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°
relevant_reflections = [
    reflection_manager.get_reflection(rid)
    for rid in reflection_ids
]

# ì„±ì°° ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
reflection_text = format_reflections(relevant_reflections)

# OpenAI LLMìœ¼ë¡œ ìµœì¢… ì§‘ê³„
final_output = result_aggregator.run(
    query=query,
    results=results,
    reflection_ids=reflection_ids,
    response_definition=response_definition
)
```

**í”„ë¡¬í”„íŠ¸:**
```
ì£¼ì–´ì§„ ëª©í‘œ:
Specific: requests, BeautifulSoup, Scrapy...

ì¡°ì‚¬ ê²°ê³¼:
Info 1: # Python ì›¹ í¬ë¡¤ë§ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¹„êµ...
Info 2: # ì›¹ í¬ë¡¤ë§ ìœ¤ë¦¬ì  ê·œì¹™...
Info 3: # ì—ëŸ¬ í•¸ë“¤ë§...
Info 4: # ì„±ëŠ¥ ìµœì í™”...

ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•  ê²ƒ:
<ref_0>
<task>requests, BeautifulSoup, Scrapy...</task>
<reflection>ì„¸ ê°€ì§€ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ë¹„êµê°€ ì²´ê³„ì ...</reflection>
</ref_0>
<ref_1>
<task>ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...</task>
<reflection>ì´ì „ í”¼ë“œë°±ì´ ì¶©ì‹¤íˆ ë°˜ì˜ë˜ì–´ í¬ê²Œ ê°œì„ ...</reflection>
</ref_1>
...
```

### ìµœì¢… ì¶œë ¥

**Anthropicì˜ ì„±ì°°ì„ ë°˜ì˜í•œ ê³ í’ˆì§ˆ ê²°ê³¼:**

```markdown
# Python ì›¹ í¬ë¡¤ëŸ¬ êµ¬í˜„ ì™„ë²½ ê°€ì´ë“œ

## ëª©ì°¨
1. ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ
2. ìœ¤ë¦¬ì  í¬ë¡¤ë§ ê·œì¹™
3. ì—ëŸ¬ í•¸ë“¤ë§
4. ì„±ëŠ¥ ìµœì í™”
5. ì‹¤ì „ í”„ë¡œì íŠ¸ ì˜ˆì œ

---

## 1. ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ

### ìƒí™©ë³„ ì¶”ì²œ

#### ì†Œê·œëª¨ í”„ë¡œì íŠ¸ (10~100 í˜ì´ì§€)
**ì¶”ì²œ:** requests + BeautifulSoup

**ì´ìœ :**
- ì„¤ì •ì´ ê°„ë‹¨í•˜ê³  ë¹ ë¥´ê²Œ ì‹œì‘ ê°€ëŠ¥
- ëŒ€ë¶€ë¶„ì˜ ì •ì  ì›¹í˜ì´ì§€ì— ì í•©
- í•™ìŠµ ê³¡ì„ ì´ ë‚®ìŒ

**ì˜ˆì œ:**
```python
import requests
from bs4 import BeautifulSoup

response = requests.get('https://example.com')
soup = BeautifulSoup(response.text, 'lxml')

# ë°ì´í„° ì¶”ì¶œ
titles = [h2.text for h2 in soup.find_all('h2')]
```

#### ì¤‘ê·œëª¨ í”„ë¡œì íŠ¸ (100~1,000 í˜ì´ì§€)
**ì¶”ì²œ:** requests + BeautifulSoup + ì»¤ìŠ¤í…€ ì—ëŸ¬ í•¸ë“¤ë§

#### ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ (1,000+ í˜ì´ì§€)
**ì¶”ì²œ:** Scrapy

**ì´ìœ :**
- ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ë¹ ë¥¸ ì†ë„
- ìë™ ì¬ì‹œë„ ë° ì—ëŸ¬ í•¸ë“¤ë§
- robots.txt ìë™ ì¤€ìˆ˜

---

## 2. ìœ¤ë¦¬ì  í¬ë¡¤ë§ ê·œì¹™

### í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### âœ… 1ë‹¨ê³„: robots.txt í™•ì¸
```python
from urllib.robotparser import RobotFileParser

def can_fetch(url, user_agent='MyBot'):
    from urllib.parse import urlparse
    parsed = urlparse(url)
    robots_url = f"{parsed.scheme}://{parsed.netloc}/robots.txt"

    rp = RobotFileParser()
    rp.set_url(robots_url)
    rp.read()

    return rp.can_fetch(user_agent, url)
```

#### âœ… 2ë‹¨ê³„: User-Agent ì„¤ì •
```python
headers = {
    'User-Agent': 'MyBot/1.0 (+https://myproject.com; contact@email.com)'
}
```

#### âœ… 3ë‹¨ê³„: ìš”ì²­ ì œí•œ
```python
import time

for url in urls:
    response = requests.get(url, headers=headers)
    time.sleep(2)  # 2ì´ˆ ëŒ€ê¸°
```

**ê¶Œì¥ ê°„ê²©:**
- ì¼ë°˜ ì‚¬ì´íŠ¸: 1~3ì´ˆ
- ëŒ€í˜• ì‚¬ì´íŠ¸: 0.5~1ì´ˆ
- ì†Œí˜• ì‚¬ì´íŠ¸: 3~5ì´ˆ

---

## 3. ì—ëŸ¬ í•¸ë“¤ë§

### ì™„ì „í•œ ì—ëŸ¬ ì²˜ë¦¬ í…œí”Œë¦¿

```python
import requests
from requests.exceptions import RequestException, Timeout, HTTPError
import time

def safe_request(url, max_retries=3):
    """ì•ˆì „í•œ HTTP ìš”ì²­ with ì¬ì‹œë„"""

    for attempt in range(max_retries):
        try:
            response = requests.get(
                url,
                timeout=10,
                headers={'User-Agent': 'MyBot/1.0'}
            )
            response.raise_for_status()  # 4xx, 5xx ì—ëŸ¬ ë°œìƒ
            return response

        except Timeout:
            print(f"íƒ€ì„ì•„ì›ƒ ë°œìƒ (ì‹œë„ {attempt+1}/{max_retries})")
            time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„

        except HTTPError as e:
            if e.response.status_code == 404:
                print("í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
            elif e.response.status_code == 429:
                print("ìš”ì²­ ì œí•œ ì´ˆê³¼, 60ì´ˆ ëŒ€ê¸°")
                time.sleep(60)
            else:
                print(f"HTTP ì—ëŸ¬: {e}")

        except RequestException as e:
            print(f"ìš”ì²­ ì‹¤íŒ¨: {e}")

    print(f"{max_retries}íšŒ ì¬ì‹œë„ í›„ ì‹¤íŒ¨")
    return None
```

---

## 4. ì„±ëŠ¥ ìµœì í™”

### ë¹„ë™ê¸° í¬ë¡¤ë§ (asyncio + aiohttp)

```python
import asyncio
import aiohttp
from bs4 import BeautifulSoup

async def fetch(session, url):
    """ë¹„ë™ê¸° HTTP ìš”ì²­"""
    async with session.get(url) as response:
        return await response.text()

async def parse(html):
    """HTML íŒŒì‹±"""
    soup = BeautifulSoup(html, 'lxml')
    return soup.find('h1').text

async def crawl_urls(urls):
    """ì—¬ëŸ¬ URLì„ ë™ì‹œì— í¬ë¡¤ë§"""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch(session, url) for url in urls]
        htmls = await asyncio.gather(*tasks)

        parse_tasks = [parse(html) for html in htmls]
        results = await asyncio.gather(*parse_tasks)

        return results

# ì‹¤í–‰
urls = ['url1', 'url2', 'url3']
results = asyncio.run(crawl_urls(urls))
```

**ì„±ëŠ¥ ë¹„êµ:**
- ë™ê¸° ì²˜ë¦¬: 100 í˜ì´ì§€ â†’ 200ì´ˆ
- ë¹„ë™ê¸° ì²˜ë¦¬: 100 í˜ì´ì§€ â†’ 10ì´ˆ (20ë°° ë¹ ë¦„)

---

## 5. ì‹¤ì „ í”„ë¡œì íŠ¸: ë‰´ìŠ¤ í¬ë¡¤ëŸ¬

### ì™„ì „í•œ êµ¬í˜„ ì˜ˆì œ

```python
import requests
from bs4 import BeautifulSoup
from urllib.robotparser import RobotFileParser
import time
import json

class EthicalNewsCrawler:
    def __init__(self, base_url):
        self.base_url = base_url
        self.user_agent = 'NewsBot/1.0 (+https://myproject.com)'
        self.results = []

        # robots.txt í™•ì¸
        self.rp = RobotFileParser()
        self.rp.set_url(f"{base_url}/robots.txt")
        self.rp.read()

    def can_fetch(self, url):
        """í¬ë¡¤ë§ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.rp.can_fetch(self.user_agent, url)

    def fetch_page(self, url):
        """í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°"""
        if not self.can_fetch(url):
            print(f"robots.txtì—ì„œ ì œí•œ: {url}")
            return None

        try:
            response = requests.get(
                url,
                headers={'User-Agent': self.user_agent},
                timeout=10
            )
            response.raise_for_status()
            time.sleep(2)  # ìš”ì²­ ì œí•œ
            return response.text

        except Exception as e:
            print(f"ì—ëŸ¬ ë°œìƒ: {e}")
            return None

    def parse_article(self, html):
        """ê¸°ì‚¬ íŒŒì‹±"""
        soup = BeautifulSoup(html, 'lxml')

        return {
            'title': soup.find('h1').text.strip(),
            'author': soup.find('span', class_='author').text.strip(),
            'content': soup.find('div', class_='content').text.strip()
        }

    def crawl(self, urls):
        """ì—¬ëŸ¬ ê¸°ì‚¬ í¬ë¡¤ë§"""
        for url in urls:
            html = self.fetch_page(url)
            if html:
                article = self.parse_article(html)
                self.results.append(article)

        return self.results

    def save_results(self, filename='results.json'):
        """ê²°ê³¼ ì €ì¥"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

# ì‚¬ìš© ì˜ˆì‹œ
crawler = EthicalNewsCrawler('https://news.example.com')
urls = [
    'https://news.example.com/article1',
    'https://news.example.com/article2'
]
results = crawler.crawl(urls)
crawler.save_results()
```

---

## 6. ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ê³µì‹ ë¬¸ì„œ
- requests: https://requests.readthedocs.io/
- BeautifulSoup: https://www.crummy.com/software/BeautifulSoup/
- Scrapy: https://docs.scrapy.org/

### ë²•ë¥  ìë£Œ
- robots.txt: https://www.robotstxt.org/
- GDPR: https://gdpr.eu/
- ê°œì¸ì •ë³´ë³´í˜¸ë²•: https://www.pipc.go.kr/

### ì„±ëŠ¥ ìµœì í™”
- aiohttp: https://docs.aiohttp.org/
- asyncio: https://docs.python.org/3/library/asyncio.html

---

## ë§ˆë¬´ë¦¬

ì´ ê°€ì´ë“œëŠ” Python ì›¹ í¬ë¡¤ëŸ¬ êµ¬í˜„ì˜ ëª¨ë“  ì¸¡ë©´ì„ ë‹¤ë£¹ë‹ˆë‹¤:
- âœ… ì ì ˆí•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ íƒ
- âœ… ìœ¤ë¦¬ì  í¬ë¡¤ë§ ê·œì¹™ ì¤€ìˆ˜
- âœ… ê°•ë ¥í•œ ì—ëŸ¬ í•¸ë“¤ë§
- âœ… ì„±ëŠ¥ ìµœì í™” ê¸°ë²•
- âœ… ì‹¤ì „ í”„ë¡œì íŠ¸ ì˜ˆì œ

**í•µì‹¬ ì›ì¹™:** í•­ìƒ robots.txtë¥¼ í™•ì¸í•˜ê³ , ì„œë²„ì— ë¶€ë‹´ì„ ì£¼ì§€ ì•Šìœ¼ë©°,
ê´€ë ¨ ë²•ë¥ ì„ ì¤€ìˆ˜í•˜ëŠ” ìœ¤ë¦¬ì ì¸ í¬ë¡¤ë§ì„ ì‹¤ì²œí•˜ì„¸ìš”.
```

---

## Cross-Reflectionì˜ í•µì‹¬ ê°€ì¹˜

### 1. êµì°¨ ê²€ì¦ (Cross-Validation)

```
OpenAIì˜ ê°•ì :
- ì½”ë“œ ìƒì„± ëŠ¥ë ¥
- ë°©ëŒ€í•œ í•™ìŠµ ë°ì´í„°
- ë¹ ë¥¸ ì¶”ë¡  ì†ë„

OpenAIì˜ ì•½ì :
- ë•Œë•Œë¡œ ê³¼ë„í•˜ê²Œ ë‚™ê´€ì 
- ì„¸ë¶€ ì‚¬í•­ ëˆ„ë½ ê°€ëŠ¥
- ì¼ê´€ì„± ìˆëŠ” í¸í–¥

â†“ Cross-Reflection â†“

Anthropicì˜ ê°•ì :
- ì—„ê²©í•œ í‰ê°€ ê¸°ì¤€
- ì„¸ë°€í•œ ë¶„ì„ ëŠ¥ë ¥
- ì•ˆì „ì„± ì¤‘ì‹œ

Anthropicì˜ ì—­í• :
- OpenAIì˜ ê²°ê³¼ë¥¼ ê°ê´€ì ìœ¼ë¡œ í‰ê°€
- ëˆ„ë½ëœ ë¶€ë¶„ ë°œê²¬
- ê°œì„  ë°©í–¥ ì œì‹œ
```

### 2. í¸í–¥ ê°ì†Œ (Bias Reduction)

**ë¬¸ì œ:**
```python
# Self-Reflection (ë™ì¼ ëª¨ë¸)
openai_llm.execute("ì½”ë“œ ì‘ì„±")
â†’ [í¸í–¥ Aê°€ í¬í•¨ëœ ì½”ë“œ]

openai_llm.reflect("ì½”ë“œ ê²€í† ")
â†’ [í¸í–¥ Aë¥¼ ì¸ì§€ ëª»í•¨] âœ… í†µê³¼
```

**í•´ê²°:**
```python
# Cross-Reflection (ë‹¤ë¥¸ ëª¨ë¸)
openai_llm.execute("ì½”ë“œ ì‘ì„±")
â†’ [í¸í–¥ Aê°€ í¬í•¨ëœ ì½”ë“œ]

anthropic_llm.reflect("ì½”ë“œ ê²€í† ")
â†’ [í¸í–¥ Aë¥¼ ë°œê²¬] âš ï¸ ì¬ì‹œë„ ìš”ì²­
```

### 3. ë‹¤ê°ë„ ë¶„ì„ (Multi-Perspective Analysis)

| ê´€ì  | OpenAI | Anthropic |
|------|--------|-----------|
| **í•™ìŠµ ë°ì´í„°** | ì›¹ í¬ë¡¤ë§ ì¤‘ì‹¬ | íë ˆì´ì…˜ëœ ë°ì´í„° |
| **í‰ê°€ ê¸°ì¤€** | ì‹¤ìš©ì„± ì¤‘ì‹œ | ì•ˆì „ì„± ì¤‘ì‹œ |
| **ì½”ë“œ ìŠ¤íƒ€ì¼** | ê°„ê²°í•¨ ì„ í˜¸ | ëª…í™•ì„± ì„ í˜¸ |
| **ì—ëŸ¬ ì²˜ë¦¬** | ê¸°ë³¸ì  ì²˜ë¦¬ | í¬ê´„ì  ì²˜ë¦¬ |

â†’ ë‘ ëª¨ë¸ì˜ ê°•ì ì„ ê²°í•©í•˜ì—¬ **ë” ì™„ì„±ë„ ë†’ì€ ê²°ê³¼** ìƒì„±

---

## ì‹¤í–‰ ì˜ˆì‹œ ë° ë¡œê·¸

### ëª…ë ¹ì–´

```bash
python -m cross_reflection.main --task "Python ì›¹ í¬ë¡¤ëŸ¬ ëª¨ë²” ì‚¬ë¡€ ì¡°ì‚¬"
```

### ì‹¤í–‰ ë¡œê·¸

```
================================================================================
ğŸ”„ Cross-Reflection Agent ì´ˆê¸°í™”
================================================================================
âœ… OpenAI LLM ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: gpt-4)
âœ… Anthropic LLM ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: claude-3-5-sonnet-20241022)
ğŸ“ Cross-Reflection ì„¤ì •: OpenAIê°€ ì‹¤í–‰, Anthropicì´ ì„±ì°° ìˆ˜í–‰

================================================================================
ğŸ¬ Self-Reflection Agent ì‹œì‘
================================================================================
ì‚¬ìš©ì ì¿¼ë¦¬: Python ì›¹ í¬ë¡¤ëŸ¬ ëª¨ë²” ì‚¬ë¡€ ì¡°ì‚¬

================================================================================
ğŸ¯ [1ë‹¨ê³„: ëª©í‘œ ì„¤ì •] ì‹œì‘
================================================================================
ğŸ¯ [ëª©í‘œ ì„¤ì •] ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•œ ëª©í‘œ ìƒì„± ì‹œì‘
  ê´€ë ¨ ê³¼ê±° íšŒê³  2ê°œ ë°œê²¬
  ê¸°ë³¸ ëª©í‘œ ìƒì„± ì™„ë£Œ: Pythonìœ¼ë¡œ ì›¹ í¬ë¡¤ëŸ¬ë¥¼ êµ¬í˜„í•  ë•Œì˜...
  ëª©í‘œ ìµœì í™” ì™„ë£Œ
ğŸ“ [ì‘ë‹µ ìµœì í™”] ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•œ ì‘ë‹µ í˜•ì‹ ì •ì˜ ì‹œì‘
  ê´€ë ¨ ê³¼ê±° íšŒê³  2ê°œ ë°œê²¬
  ì‘ë‹µ í˜•ì‹ ì •ì˜ ì™„ë£Œ
âœ… [1ë‹¨ê³„: ëª©í‘œ ì„¤ì •] ì™„ë£Œ

================================================================================
ğŸ“‹ [2ë‹¨ê³„: ëª©í‘œ ë¶„í•´] ì‹œì‘
================================================================================
ğŸ“‹ [ëª©í‘œ ë¶„í•´] ê³¼ê±° íšŒê³ ë¥¼ ê³ ë ¤í•œ íƒœìŠ¤í¬ ë¶„í•´ ì‹œì‘
  ê´€ë ¨ ê³¼ê±° íšŒê³  2ê°œ ë°œê²¬
  íƒœìŠ¤í¬ ë¶„í•´ ì™„ë£Œ: ì´ 4ê°œì˜ íƒœìŠ¤í¬ ìƒì„±
    íƒœìŠ¤í¬ 1: requests, BeautifulSoup, Scrapy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜...
    íƒœìŠ¤í¬ 2: ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...
    íƒœìŠ¤í¬ 3: ì›¹ í¬ë¡¤ëŸ¬ì˜ ì—ëŸ¬ í•¸ë“¤ë§ íŒ¨í„´...
    íƒœìŠ¤í¬ 4: ì›¹ í¬ë¡¤ëŸ¬ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•...
âœ… [2ë‹¨ê³„: ëª©í‘œ ë¶„í•´] ì™„ë£Œ

ğŸ“ [3ë‹¨ê³„: íƒœìŠ¤í¬ ì‹¤í–‰] íƒœìŠ¤í¬ 1/4 ì‹¤í–‰
âš™ï¸  [íƒœìŠ¤í¬ ì‹¤í–‰] ì‹œì‘: requests, BeautifulSoup, Scrapy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜...
  ê´€ë ¨ ê³¼ê±° íšŒê³  2ê°œ ì ìš©
  íƒœìŠ¤í¬ ì‹¤í–‰ ì™„ë£Œ (ê²°ê³¼ ê¸¸ì´: 2847 ê¸€ì)
ğŸ” [ìê¸° ì„±ì°°] íƒœìŠ¤í¬ 1 ê²°ê³¼ ê²€í†  ì¤‘...
  âœ… ì„±ì°° í†µê³¼
  ì„±ì°° ë‚´ìš©: ì„¸ ê°€ì§€ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ë¹„êµê°€ ì²´ê³„ì ì´ê³ ...

â¡ï¸  ë‹¤ìŒ íƒœìŠ¤í¬ë¡œ ì§„í–‰

ğŸ“Œ íƒœìŠ¤í¬ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸: 0 â†’ 1

ğŸ“ [3ë‹¨ê³„: íƒœìŠ¤í¬ ì‹¤í–‰] íƒœìŠ¤í¬ 2/4 ì‹¤í–‰
âš™ï¸  [íƒœìŠ¤í¬ ì‹¤í–‰] ì‹œì‘: ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...
  ê´€ë ¨ ê³¼ê±° íšŒê³  3ê°œ ì ìš©
  íƒœìŠ¤í¬ ì‹¤í–‰ ì™„ë£Œ (ê²°ê³¼ ê¸¸ì´: 1234 ê¸€ì)
ğŸ” [ìê¸° ì„±ì°°] íƒœìŠ¤í¬ 2 ê²°ê³¼ ê²€í†  ì¤‘...
  âš ï¸  ì¬ì‹œë„ í•„ìš”: ìœ¤ë¦¬ì  ê·œì¹™ì˜ ì£¼ìš” í•­ëª©ë“¤ì€ ì–¸ê¸‰ë˜ì—ˆìœ¼ë‚˜...
  ì„±ì°° ë‚´ìš©: íŠ¹íˆ ë‹¤ìŒ ë¶€ë¶„ë“¤ì´ ê°œì„  í•„ìš”: 1. robots.txtë¥¼ ì‹¤ì œë¡œ...

â†©ï¸  ì¬ì‹œë„ ê²°ì •: í˜„ì¬ ì¬ì‹œë„ íšŸìˆ˜ 1/2

ğŸ”„ [ì¬ì‹œë„ 1íšŒì°¨] íƒœìŠ¤í¬ 2/4 ì¬ì‹¤í–‰
âš™ï¸  [íƒœìŠ¤í¬ ì‹¤í–‰] ì‹œì‘: ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...
  ê´€ë ¨ ê³¼ê±° íšŒê³  4ê°œ ì ìš©
  íƒœìŠ¤í¬ ì‹¤í–‰ ì™„ë£Œ (ê²°ê³¼ ê¸¸ì´: 4521 ê¸€ì)
ğŸ” [ìê¸° ì„±ì°°] íƒœìŠ¤í¬ 2 ê²°ê³¼ ê²€í†  ì¤‘...
  âœ… ì„±ì°° í†µê³¼
  ì„±ì°° ë‚´ìš©: ì´ì „ í”¼ë“œë°±ì´ ì¶©ì‹¤íˆ ë°˜ì˜ë˜ì–´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤...

â¡ï¸  ë‹¤ìŒ íƒœìŠ¤í¬ë¡œ ì§„í–‰

[... íƒœìŠ¤í¬ 3, 4 ì‹¤í–‰ ...]

âœ… ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ

================================================================================
ğŸ“Š [4ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„] ì‹œì‘
================================================================================
ğŸ“Š [ê²°ê³¼ ì§‘ê³„] ê³¼ê±° íšŒê³ ë¥¼ ë°˜ì˜í•œ ìµœì¢… ê²°ê³¼ ìƒì„± ì‹œì‘
  ìˆ˜ì§‘ëœ ê²°ê³¼ ê°œìˆ˜: 4ê°œ
  ì°¸ì¡°í•  íšŒê³  ê°œìˆ˜: 5ê°œ
  ê²°ê³¼ ì§‘ê³„ ì™„ë£Œ (ìµœì¢… ê²°ê³¼ ê¸¸ì´: 8934 ê¸€ì)
âœ… [4ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„] ì™„ë£Œ

================================================================================
ğŸ‰ Self-Reflection Agent ì™„ë£Œ
================================================================================

================================================================================
ğŸ“„ ìµœì¢… ê²°ê³¼
================================================================================
# Python ì›¹ í¬ë¡¤ëŸ¬ êµ¬í˜„ ì™„ë²½ ê°€ì´ë“œ
...
```

---

## ì €ì¥ëœ ì„±ì°° ë°ì´í„°

**íŒŒì¼:** `tmp/cross_reflection_db.json`

```json
[
  {
    "reflection": {
      "id": "abc123",
      "task": "requests, BeautifulSoup, Scrapy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ íŠ¹ì§•...",
      "reflection": "ì„¸ ê°€ì§€ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ëŒ€í•œ ë¹„êµê°€ ì²´ê³„ì ì´ê³ ...",
      "judgment": {
        "needs_retry": false,
        "confidence": 0.9,
        "reasons": [
          "ì„¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•µì‹¬ íŠ¹ì§•ì´ ëª…í™•í•˜ê²Œ ì„¤ëª…ë¨",
          "ì½”ë“œ ì˜ˆì œê°€ ì‹¤ìš©ì ì´ê³  ì£¼ì„ì´ ì˜ ë‹¬ë ¤ ìˆìŒ"
        ]
      }
    },
    "embedding": [0.123, 0.456, ...]
  },
  {
    "reflection": {
      "id": "def456",
      "task": "ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...",
      "reflection": "ìœ¤ë¦¬ì  ê·œì¹™ì˜ ì£¼ìš” í•­ëª©ë“¤ì€ ì–¸ê¸‰ë˜ì—ˆìœ¼ë‚˜...",
      "judgment": {
        "needs_retry": true,
        "confidence": 0.85,
        "reasons": [
          "ì£¼ìš” í•­ëª©ì€ ë‹¤ë¤˜ìœ¼ë‚˜ ê¹Šì´ê°€ ë¶€ì¡±í•¨",
          "ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì œê°€ ë¯¸í¡í•¨"
        ]
      }
    },
    "embedding": [0.789, 0.012, ...]
  },
  {
    "reflection": {
      "id": "ghi789",
      "task": "ì›¹ í¬ë¡¤ë§ ì‹œ ì¤€ìˆ˜í•´ì•¼ í•  ìœ¤ë¦¬ì  ê·œì¹™...",
      "reflection": "ì´ì „ í”¼ë“œë°±ì´ ì¶©ì‹¤íˆ ë°˜ì˜ë˜ì–´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤...",
      "judgment": {
        "needs_retry": false,
        "confidence": 0.95,
        "reasons": [
          "ëª¨ë“  ìœ¤ë¦¬ì  ê·œì¹™ì´ ì‹¤ë¬´ ìˆ˜ì¤€ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ë‹¤ë¤„ì§",
          "ì™„ì „íˆ ë™ì‘í•˜ëŠ” ì½”ë“œ ì˜ˆì œ ì œê³µ"
        ]
      }
    },
    "embedding": [0.345, 0.678, ...]
  }
]
```

---

## í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. ì½”ë“œ ë¦¬ë·° ì—ì´ì „íŠ¸

```python
# OpenAI: ì½”ë“œ ì‘ì„±
# Anthropic: ë³´ì•ˆ, ì„±ëŠ¥, ê°€ë…ì„± ë¦¬ë·°
task = "ì•ˆì „í•œ ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œ êµ¬í˜„"
```

### 2. ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±

```python
# OpenAI: ë¬¸ì„œ ì´ˆì•ˆ ì‘ì„±
# Anthropic: ì •í™•ì„±, ì™„ì„±ë„, ëª…í™•ì„± ê²€ì¦
task = "REST API ì„¤ê³„ ê°€ì´ë“œ ì‘ì„±"
```

### 3. ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸

```python
# OpenAI: ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”
# Anthropic: ê²°ë¡ ì˜ íƒ€ë‹¹ì„±, í¸í–¥ ê²€ì¦
task = "ì›”ê°„ íŒë§¤ ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"
```

---

## ë¹„ìš© ê³ ë ¤ì‚¬í•­

### Self-Reflection vs Cross-Reflection ë¹„ìš©

**Self-Reflection:**
- ì‹¤í–‰: GPT-4 (4ê°œ íƒœìŠ¤í¬)
- ì„±ì°°: GPT-4 (4ê°œ ì„±ì°°)
- **ì´ ë¹„ìš©**: ~$0.20

**Cross-Reflection:**
- ì‹¤í–‰: GPT-4 (4ê°œ íƒœìŠ¤í¬)
- ì„±ì°°: Claude (4ê°œ ì„±ì°°)
- **ì´ ë¹„ìš©**: ~$0.22 (+10%)

**ê²°ë¡ :** ë¹„ìš©ì´ ì•½ê°„ ì¦ê°€í•˜ì§€ë§Œ, **í’ˆì§ˆ ê°œì„ **ìœ¼ë¡œ ì¶©ë¶„íˆ ìƒì‡„ë¨

---

## ì£¼ìš” í´ë˜ìŠ¤ ë° í•¨ìˆ˜ ì°¸ì¡°

### Cross-Reflection ê³ ìœ  ì½”ë“œ
- [main.py](main.py): ì „ì²´ ì§„ì…ì 
- [main.py#L52-L86](main.py#L52-L86): LLM ì´ˆê¸°í™” ë° ì—ì´ì „íŠ¸ êµ¬ì„±

### Self-Reflection ì¸í”„ë¼ (ì¬ì‚¬ìš©)
- [ReflectiveAgent](../self_reflection/main.py#L245-L395): ì „ì²´ ì›Œí¬í”Œë¡œìš°
- [TaskReflector](../common/reflection_manager.py#L112-L144): ì„±ì°° ìˆ˜í–‰
- [ReflectionManager](../common/reflection_manager.py#L39-L109): ì„±ì°° ë°ì´í„° ê´€ë¦¬

### ì›Œí¬í”Œë¡œìš° ë…¸ë“œ
- [_goal_setting](../self_reflection/main.py#L298-L310): ëª©í‘œ ì„¤ì •
- [_decompose_query](../self_reflection/main.py#L312-L318): ëª©í‘œ ë¶„í•´
- [_execute_task](../self_reflection/main.py#L320-L329): íƒœìŠ¤í¬ ì‹¤í–‰
- [_reflect_on_task](../self_reflection/main.py#L331-L349): ì„±ì°° ìˆ˜í–‰
- [_aggregate_results](../self_reflection/main.py#L372-L383): ê²°ê³¼ ì§‘ê³„

---

## í•µì‹¬ í¬ì¸íŠ¸

### 1. Cross-Reflectionì€ ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ê°€?

**ì‚¬ìš© ê¶Œì¥:**
- âœ… ë†’ì€ í’ˆì§ˆì´ ì¤‘ìš”í•œ ê²½ìš°
- âœ… ì¤‘ìš”í•œ ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•œ ê²½ìš°
- âœ… ë‹¤ê°ë„ ê²€ì¦ì´ í•„ìš”í•œ ê²½ìš°
- âœ… ë‹¨ì¼ ëª¨ë¸ì˜ í¸í–¥ì„ í”¼í•˜ê³  ì‹¶ì€ ê²½ìš°

**ì‚¬ìš© ë¹„ê¶Œì¥:**
- âŒ ê°„ë‹¨í•œ íƒœìŠ¤í¬
- âŒ ë¹„ìš©ì´ ë§¤ìš° ì œí•œì ì¸ ê²½ìš°
- âŒ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ ë‹¨ê³„

### 2. êµ¬í˜„ì˜ ë‹¨ìˆœí•¨

Cross-Reflectionì€ **Self-Reflectionì˜ ì¸í”„ë¼ë¥¼ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©**í•©ë‹ˆë‹¤.

**í•„ìš”í•œ ë³€ê²½:**
1. Anthropic LLM ì¶”ê°€ ì´ˆê¸°í™”
2. TaskReflectorì— Anthropic LLM ì „ë‹¬
3. ë!

```python
# ë‹¨ 3ì¤„ì˜ ë³€ê²½ìœ¼ë¡œ Cross-Reflection êµ¬í˜„
anthropic_llm = ChatAnthropic(model="claude")
task_reflector = TaskReflector(llm=anthropic_llm)  # Anthropic ì‚¬ìš©
agent = ReflectiveAgent(llm=openai_llm, task_reflector=task_reflector)
```

### 3. ìƒí˜¸ ë³´ì™„ì  ê°•ì 

| ë‹¨ê³„ | ì‚¬ìš© LLM | ê°•ì  í™œìš© |
|------|---------|----------|
| ëª©í‘œ ì„¤ì • | OpenAI | ì°½ì˜ì  ëª©í‘œ ìƒì„± |
| ëª©í‘œ ë¶„í•´ | OpenAI | ì‹¤í–‰ ê°€ëŠ¥í•œ íƒœìŠ¤í¬ ë„ì¶œ |
| íƒœìŠ¤í¬ ì‹¤í–‰ | OpenAI | ë¹ ë¥¸ ì •ë³´ ìˆ˜ì§‘ |
| **ì„±ì°°** | **Anthropic** | **ì—„ê²©í•œ í’ˆì§ˆ ê²€ì¦** â­ |
| ê²°ê³¼ ì§‘ê³„ | OpenAI | ì¼ê´€ëœ ë¬¸ì„œ ì‘ì„± |

### 4. í’ˆì§ˆ vs ë¹„ìš© íŠ¸ë ˆì´ë“œì˜¤í”„

```
Self-Reflection:
í’ˆì§ˆ: â­â­â­â­ (Good)
ë¹„ìš©: $ (ì €ë ´)
ì†ë„: ë¹ ë¦„

Cross-Reflection:
í’ˆì§ˆ: â­â­â­â­â­ (Excellent)
ë¹„ìš©: $$ (ì•½ê°„ ë¹„ìŒˆ)
ì†ë„: ì•½ê°„ ëŠë¦¼

â†’ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ì—ì„œëŠ” Cross-Reflection ê¶Œì¥
```

---

## ë‹¤ìŒ ë‹¨ê³„

Cross-Reflectionì„ ë§ˆìŠ¤í„°í–ˆë‹¤ë©´ ë‹¤ìŒì„ í•™ìŠµí•´ë³´ì„¸ìš”:

1. **Multi-Agent Collaboration**: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥
2. **Role-Based Cooperation**: ì—­í•  ë¶„ë‹´ ê¸°ë°˜ í˜‘ì—…
3. **Prompt Optimizer**: ë” ë‚˜ì€ í”„ë¡¬í”„íŠ¸ ìƒì„±

---

## ì°¸ê³  ìë£Œ

### ì½”ë“œ
- [cross_reflection/main.py](main.py)
- [self_reflection/main.py](../self_reflection/main.py)
- [common/reflection_manager.py](../common/reflection_manager.py)

### ê°œë…
- Self-Reflection íŒ¨í„´: [FLOW_DETAILED.md](../self_reflection/FLOW_DETAILED.md)
- ReAct íŒ¨í„´: Yao et al. (2022)
- Cross-Validation: ë¨¸ì‹ ëŸ¬ë‹ ê²€ì¦ ê¸°ë²•

### LLM ì œê³µì
- OpenAI: https://platform.openai.com/docs
- Anthropic: https://docs.anthropic.com/
